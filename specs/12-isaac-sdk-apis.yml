---
chapter_id: "12-isaac-sdk-apis"
title: "Isaac SDK & APIs"
module_id: "M4-isaac-brain"
module_title: "NVIDIA Isaac Brain"
overview: "This chapter delves into the NVIDIA Isaac SDK and its comprehensive set of APIs for developing robotics applications. Students will learn to use Isaac's software development tools, including Isaac Apps, Isaac Extensions, and Isaac Messages. The chapter covers Isaac's Python and C++ APIs, GPU-accelerated libraries, and how to build custom robotics applications using the Isaac framework. Students will also explore Isaac's simulation APIs and how to extend Isaac functionality through custom extensions."
why_it_matters: "Understanding the Isaac SDK and APIs is crucial for leveraging the full potential of the Isaac platform. The SDK provides optimized libraries for perception, navigation, and manipulation that take advantage of NVIDIA's GPU computing capabilities. Mastering these APIs enables developers to build efficient, high-performance robotics applications that can process sensor data, make intelligent decisions, and control robots in real-time."
key_concepts:
  - "Isaac Message Format: Understanding Isaac's message structure and serialization"
  - "Isaac Extensions: Creating custom extensions and plugins for Isaac applications"
  - "GPU-Accelerated Libraries: Using TensorRT, cuDNN, and other NVIDIA libraries"
  - "Isaac Apps Framework: Building applications with Isaac's modular architecture"
  - "Simulation APIs: Controlling and extending Isaac Sim programmatically"
  - "Perception Pipeline APIs: Building custom perception systems"
  - "Navigation APIs: Implementing GPU-accelerated navigation"
  - "Extension Development: Creating reusable Isaac components"

code_examples:
  -
    title: "Isaac Extension Development"
    description: "Creating a custom Isaac extension for robot perception processing"
    language: "python"
    framework: "Isaac Python API"
    code: |
      #!/usr/bin/env python3
      """
      Isaac Extension for Custom Perception Processing
      This extension demonstrates how to create custom perception modules in Isaac
      """
      import carb
      import omni
      from omni.isaac.core import World
      from omni.isaac.core.utils.viewports import set_camera_view
      from omni.isaac.core.utils.stage import add_reference_to_stage
      from omni.isaac.core.utils.prims import get_prim_at_path
      from omni.isaac.core.utils.nucleus import get_assets_root_path
      from omni.isaac.core.objects import DynamicCuboid
      from omni.isaac.core.materials import PhysicsMaterial
      import numpy as np
      import cv2
      from pxr import Gf, Sdf, UsdGeom, UsdShade, UsdPhysics
      import omni.replicator.core as rep
      import omni.kit.commands

      # Isaac extension class
      class CustomPerceptionExtension:
          def __init__(self):
              self.world = None
              self.robot = None
              self.camera = None
              self.perception_pipeline = None

          def setup_world(self):
              """Initialize the Isaac world with objects"""
              self.world = World(stage_units_in_meters=1.0)

              # Add ground plane
              self.world.scene.add_default_ground_plane()

              # Add a cube for perception
              cube = self.world.scene.add(
                  DynamicCuboid(
                      prim_path="/World/Cube",
                      name="cube",
                      position=np.array([1.0, 0.0, 0.5]),
                      size=0.2,
                      color=np.array([0.8, 0.2, 0.1])
                  )
              )

              # Add physics material
              material = PhysicsMaterial(
                  prim_path="/World/lite_material",
                  static_friction=0.5,
                  dynamic_friction=0.5,
                  restitution=0.8
              )
              cube.set_material(material)

          def setup_camera(self):
              """Setup camera for perception"""
              # Create a camera prim
              camera_path = "/World/Camera"
              camera_prim = self.world.scene.stage.DefinePrim(camera_path, "Camera")

              # Set camera properties
              camera = UsdGeom.Camera(camera_prim)
              camera.GetFocalLengthAttr().Set(24.0)
              camera.GetHorizontalApertureAttr().Set(20.955)
              camera.GetVerticalApertureAttr().Set(15.2908)

              # Position the camera
              xform = UsdGeom.Xformable(camera_prim)
              xform.AddTranslateOp().Set(Gf.Vec3d(2.0, 0.0, 1.0))
              xform.AddRotateYOp().Set(-90.0)  # Point toward the cube

          def setup_perception_pipeline(self):
              """Setup Isaac Replicator for synthetic data generation"""
              # Enable Isaac Replicator
              rep.orchestrator._orchestrator = None
              rep.orchestrator.setup_camera("/World/Camera")

              # Create a simple texture
              with rep.new_layer():
                  # Create a material
                  material = rep.create.from_usd(
                      prim_path="/World/Materials",
                      usd_path="material.usd"
                  )

                  # Annotate objects for segmentation
                  with rep.randomizer.augmentations():
                      cube = rep.get.prims(path_pattern="Cube")
                      with cube:
                          rep.randomizer.annotate(
                              prim_types="Cube",
                              labels="obstacle"
                          )

          def run_perception_processing(self):
              """Run the perception processing pipeline"""
              # Initialize the world
              self.setup_world()
              self.setup_camera()
              self.setup_perception_pipeline()

              # Reset the world
              self.world.reset()

              # Run perception for a number of steps
              for i in range(100):
                  self.world.step(render=True)

                  # Get camera data
                  if i % 10 == 0:  # Process every 10 steps
                      self.process_camera_data()

          def process_camera_data(self):
              """Process camera data for perception"""
              # This is a simplified example
              # In real Isaac, this would connect to actual camera sensors
              carb.log_info("Processing camera data for perception...")

              # Example: Synthetic data generation
              synthetic_image = np.random.rand(480, 640, 3) * 255
              synthetic_image = synthetic_image.astype(np.uint8)

              # Process synthetic image
              processed_data = self.analyze_image(synthetic_image)
              carb.log_info(f"Perception analysis complete: {processed_data}")

          def analyze_image(self, image):
              """Analyze image data for object detection"""
              # Example analysis (in real Isaac, this would use GPU-accelerated models)
              height, width = image.shape[:2]
              center_x, center_y = width // 2, height // 2

              # Simple analysis - find dominant color in center region
              center_region = image[center_y-50:center_y+50, center_x-50:center_x+50]
              dominant_color = np.mean(center_region, axis=(0, 1))

              return {
                  "dominant_color": dominant_color.tolist(),
                  "image_shape": [height, width],
                  "analysis_timestamp": carb.events.acquire_events_interface().get_current_time()
              }

      # Extension registration
      class IsaacPerceptionExtension:
          def __init__(self):
              self.perception_ext = CustomPerceptionExtension()

          def on_startup(self, ext_id):
              carb.log_info("[isaac_perception_extension] Starting up...")

          def on_shutdown(self):
              carb.log_info("[isaac_perception_extension] Shutting down...")

          def run_perception_demo(self):
              """Run the perception demonstration"""
              carb.log_info("Starting perception extension demo...")
              self.perception_ext.run_perception_processing()

      # Example usage
      def main():
          """Main function to demonstrate the extension"""
          carb.log_info("Initializing Isaac Perception Extension...")

          # Create extension instance
          ext = IsaacPerceptionExtension()

          # Start up
          ext.on_startup("isaac_perception_extension")

          # Run demo
          ext.run_perception_demo()

          # Shutdown
          ext.on_shutdown()

      if __name__ == "__main__":
          main()

  -
    title: "Isaac Message Handling"
    description: "Implementation of Isaac message handling for robotics communication"
    language: "python"
    framework: "Isaac Python API"
    code: |
      #!/usr/bin/env python3
      """
      Isaac Message Handling System
      Demonstrates Isaac's message format and communication patterns
      """
      import json
      import time
      import threading
      import queue
      import numpy as np
      from dataclasses import dataclass, asdict
      from typing import Dict, Any, Optional
      import uuid

      # Isaac message structure
      @dataclass
      class IsaacMessage:
          """Base Isaac message structure"""
          id: str
          timestamp: float
          source: str
          destination: str
          message_type: str
          data: Dict[str, Any]
          metadata: Dict[str, Any]

          def to_json(self) -> str:
              """Convert message to JSON format"""
              return json.dumps({
                  'id': self.id,
                  'timestamp': self.timestamp,
                  'source': self.source,
                  'destination': self.destination,
                  'message_type': self.message_type,
                  'data': self.data,
                  'metadata': self.metadata
              })

          @classmethod
          def from_json(cls, json_str: str):
              """Create message from JSON string"""
              data = json.loads(json_str)
              return cls(**data)

      class IsaacMessageBroker:
          """Isaac message broker for handling robot communication"""
          def __init__(self):
              self.message_queue = queue.Queue()
              self.subscribers = {}
              self.message_handlers = {}
              self.running = False
              self.broker_thread = None

          def register_subscriber(self, topic: str, callback):
              """Register a subscriber for a topic"""
              if topic not in self.subscribers:
                  self.subscribers[topic] = []
              self.subscribers[topic].append(callback)

          def register_handler(self, message_type: str, handler):
              """Register a handler for specific message types"""
              self.message_handlers[message_type] = handler

          def send_message(self, message: IsaacMessage):
              """Send a message to the broker"""
              self.message_queue.put(message)

          def publish(self, topic: str, message: IsaacMessage):
              """Publish message to specific topic"""
              # Add topic to metadata
              message.metadata['topic'] = topic
              self.send_message(message)

          def start(self):
              """Start the message broker"""
              self.running = True
              self.broker_thread = threading.Thread(target=self._broker_loop)
              self.broker_thread.start()

          def stop(self):
              """Stop the message broker"""
              self.running = False
              if self.broker_thread:
                  self.broker_thread.join()

          def _broker_loop(self):
              """Main broker loop"""
              while self.running:
                  try:
                      # Get message from queue
                      message = self.message_queue.get(timeout=0.1)

                      # Handle message based on type
                      if message.message_type in self.message_handlers:
                          handler = self.message_handlers[message.message_type]
                          handler(message)

                      # Publish to subscribers if topic exists
                      topic = message.metadata.get('topic')
                      if topic and topic in self.subscribers:
                          for callback in self.subscribers[topic]:
                              try:
                                  callback(message)
                              except Exception as e:
                                  print(f"Error in subscriber callback: {e}")

                  except queue.Empty:
                      continue  # Continue loop if no messages

      class IsaacPerceptionMessageHandler:
          """Handler for perception-related messages in Isaac"""
          def __init__(self, broker: IsaacMessageBroker):
              self.broker = broker
              self.perception_results = {}
              self.setup_handlers()

          def setup_handlers(self):
              """Setup message handlers for perception"""
              self.broker.register_handler('sensor_data', self.handle_sensor_data)
              self.broker.register_handler('detection_result', self.handle_detection_result)
              self.broker.register_handler('pose_estimation', self.handle_pose_estimation)

              # Register for specific topics
              self.broker.register_subscriber('/isaac/sensors/camera', self.camera_callback)
              self.broker.register_subscriber('/isaac/perception/detections', self.detection_callback)

          def handle_sensor_data(self, message: IsaacMessage):
              """Handle incoming sensor data"""
              sensor_type = message.data.get('sensor_type', 'unknown')
              sensor_data = message.data.get('sensor_data', {})

              print(f"Processing {sensor_type} sensor data...")

              # Process sensor data based on type
              if sensor_type == 'camera':
                  self.process_camera_data(sensor_data)
              elif sensor_type == 'lidar':
                  self.process_lidar_data(sensor_data)
              elif sensor_type == 'imu':
                  self.process_imu_data(sensor_data)

          def handle_detection_result(self, message: IsaacMessage):
              """Handle detection results"""
              detections = message.data.get('detections', [])
              confidence_threshold = message.data.get('confidence_threshold', 0.5)

              # Filter detections by confidence
              filtered_detections = [
                  det for det in detections
                  if det.get('confidence', 0) >= confidence_threshold
              ]

              # Store results
              detection_id = message.id
              self.perception_results[detection_id] = {
                  'detections': filtered_detections,
                  'timestamp': message.timestamp,
                  'source': message.source
              }

              print(f"Processed {len(filtered_detections)} detections with confidence > {confidence_threshold}")

          def handle_pose_estimation(self, message: IsaacMessage):
              """Handle pose estimation results"""
              pose_data = message.data.get('pose_data', {})
              object_id = message.data.get('object_id', 'unknown')

              # Process pose data
              position = pose_data.get('position', [0, 0, 0])
              orientation = pose_data.get('orientation', [0, 0, 0, 1])  # w, x, y, z quaternion

              print(f"Estimated pose for {object_id}: pos={position}, orient={orientation}")

          def process_camera_data(self, sensor_data):
              """Process camera sensor data"""
              # In Isaac, this would connect to actual camera streams
              width = sensor_data.get('width', 640)
              height = sensor_data.get('height', 480)
              encoding = sensor_data.get('encoding', 'rgb8')

              # Simulate processing
              print(f"Processing camera data: {width}x{height} {encoding}")

              # GPU-accelerated processing would happen here
              # For example: object detection, feature extraction, etc.

          def process_lidar_data(self, sensor_data):
              """Process LIDAR sensor data"""
              # In Isaac, this would connect to actual LIDAR streams
              points = sensor_data.get('points', [])
              ranges = sensor_data.get('ranges', [])

              print(f"Processing LIDAR data: {len(points)} points, {len(ranges)} ranges")

              # GPU-accelerated processing would happen here
              # For example: segmentation, clustering, etc.

          def process_imu_data(self, sensor_data):
              """Process IMU sensor data"""
              linear_acceleration = sensor_data.get('linear_acceleration', [0, 0, 0])
              angular_velocity = sensor_data.get('angular_velocity', [0, 0, 0])
              orientation = sensor_data.get('orientation', [0, 0, 0, 1])

              print(f"Processing IMU data: accel={linear_acceleration}, gyro={angular_velocity}")

          def camera_callback(self, message: IsaacMessage):
              """Callback for camera messages"""
              print(f"Received camera message from {message.source}")

          def detection_callback(self, message: IsaacMessage):
              """Callback for detection messages"""
              print(f"Received detection message from {message.source}")

      class IsaacNavigationMessageHandler:
          """Handler for navigation-related messages in Isaac"""
          def __init__(self, broker: IsaacMessageBroker):
              self.broker = broker
              self.navigation_state = {
                  'current_pose': [0, 0, 0],  # x, y, theta
                  'current_velocity': [0, 0],  # linear, angular
                  'goal_pose': [0, 0, 0],
                  'path': [],
                  'status': 'idle'
              }
              self.setup_handlers()

          def setup_handlers(self):
              """Setup navigation message handlers"""
              self.broker.register_handler('navigation_goal', self.handle_navigation_goal)
              self.broker.register_handler('path_plan', self.handle_path_plan)
              self.broker.register_handler('velocity_command', self.handle_velocity_command)

          def handle_navigation_goal(self, message: IsaacMessage):
              """Handle navigation goal messages"""
              goal_pose = message.data.get('goal_pose', [0, 0, 0])
              self.navigation_state['goal_pose'] = goal_pose
              self.navigation_state['status'] = 'planning'

              print(f"Received navigation goal: {goal_pose}")

              # Trigger path planning
              self.plan_path_to_goal()

          def handle_path_plan(self, message: IsaacMessage):
              """Handle path planning results"""
              path = message.data.get('path', [])
              self.navigation_state['path'] = path
              self.navigation_state['status'] = 'executing'

              print(f"Received path with {len(path)} waypoints")

          def handle_velocity_command(self, message: IsaacMessage):
              """Handle velocity command messages"""
              linear_vel = message.data.get('linear_velocity', 0.0)
              angular_vel = message.data.get('angular_velocity', 0.0)

              self.navigation_state['current_velocity'] = [linear_vel, angular_vel]
              self.navigation_state['status'] = 'moving'

              print(f"Executing velocity command: linear={linear_vel}, angular={angular_vel}")

          def plan_path_to_goal(self):
              """Plan path to current goal (simplified)"""
              current = self.navigation_state['current_pose']
              goal = self.navigation_state['goal_pose']

              # Simple path planning (in Isaac, this would be GPU-accelerated)
              path = []
              steps = 10
              for i in range(steps + 1):
                  t = i / steps
                  x = current[0] + t * (goal[0] - current[0])
                  y = current[1] + t * (goal[1] - current[1])
                  theta = current[2] + t * (goal[2] - current[2])
                  path.append([x, y, theta])

              # Create path planning result message
              path_msg = IsaacMessage(
                  id=str(uuid.uuid4()),
                  timestamp=time.time(),
                  source='path_planner',
                  destination='navigation_controller',
                  message_type='path_plan',
                  data={'path': path},
                  metadata={'planner': 'isaac_path_planner'}
              )

              self.broker.send_message(path_msg)

      def main():
          """Main function demonstrating Isaac message handling"""
          print("Initializing Isaac Message System...")

          # Create message broker
          broker = IsaacMessageBroker()

          # Create message handlers
          perception_handler = IsaacPerceptionMessageHandler(broker)
          navigation_handler = IsaacNavigationMessageHandler(broker)

          # Start broker
          broker.start()

          # Simulate sending some messages
          time.sleep(1)

          # Send sensor data message
          sensor_msg = IsaacMessage(
              id=str(uuid.uuid4()),
              timestamp=time.time(),
              source='camera_sensor',
              destination='perception_module',
              message_type='sensor_data',
              data={
                  'sensor_type': 'camera',
                  'sensor_data': {
                      'width': 640,
                      'height': 480,
                      'encoding': 'rgb8'
                  }
              },
              metadata={'priority': 'high'}
          )

          broker.send_message(sensor_msg)

          # Send navigation goal
          goal_msg = IsaacMessage(
              id=str(uuid.uuid4()),
              timestamp=time.time(),
              source='task_manager',
              destination='navigation_module',
              message_type='navigation_goal',
              data={
                  'goal_pose': [2.0, 2.0, 0.0]
              },
              metadata={'urgency': 'normal'}
          )

          broker.send_message(goal_msg)

          # Let it run for a few seconds
          time.sleep(5)

          # Stop broker
          broker.stop()
          print("Isaac Message System stopped.")

      if __name__ == "__main__":
          main()

  -
    title: "Isaac Apps Framework Integration"
    description: "Integration with Isaac Apps framework for building modular robotics applications"
    language: "python"
    framework: "Isaac Apps API"
    code: |
      #!/usr/bin/env python3
      """
      Isaac Apps Framework Integration
      Demonstrates how to build modular robotics applications using Isaac Apps
      """
      import argparse
      import json
      import time
      import threading
      import numpy as np
      from dataclasses import dataclass, field
      from typing import Dict, List, Callable, Any
      import logging

      # Configure logging
      logging.basicConfig(level=logging.INFO)
      logger = logging.getLogger(__name__)

      @dataclass
      class IsaacAppConfig:
          """Configuration for Isaac App"""
          app_name: str
          app_version: str
          components: List[str]
          parameters: Dict[str, Any]
          dependencies: List[str]
          gpu_required: bool = True

      class IsaacAppComponent:
          """Base class for Isaac App components"""
          def __init__(self, name: str, config: Dict[str, Any]):
              self.name = name
              self.config = config
              self.initialized = False
              self.running = False

          def initialize(self):
              """Initialize the component"""
              logger.info(f"Initializing component: {self.name}")
              self.initialized = True

          def start(self):
              """Start the component"""
              if not self.initialized:
                  self.initialize()
              logger.info(f"Starting component: {self.name}")
              self.running = True

          def stop(self):
              """Stop the component"""
              logger.info(f"Stopping component: {self.name}")
              self.running = False

          def update(self):
              """Update component logic"""
              pass

          def get_status(self):
              """Get component status"""
              return {
                  'name': self.name,
                  'initialized': self.initialized,
                  'running': self.running,
                  'config': self.config
              }

      class IsaacPerceptionComponent(IsaacAppComponent):
          """Perception component for Isaac Apps"""
          def __init__(self, name: str, config: Dict[str, Any]):
              super().__init__(name, config)
              self.models = {}
              self.sensors = []
              self.detection_results = []

          def initialize(self):
              """Initialize perception component"""
              super().initialize()

              # Load perception models
              model_paths = self.config.get('model_paths', [])
              for model_path in model_paths:
                  self.load_model(model_path)

              # Initialize sensors
              sensor_configs = self.config.get('sensors', [])
              for sensor_config in sensor_configs:
                  self.add_sensor(sensor_config)

          def load_model(self, model_path: str):
              """Load a perception model (simplified)"""
              logger.info(f"Loading perception model: {model_path}")
              # In Isaac, this would load TensorRT models for GPU acceleration
              self.models[model_path] = {
                  'loaded': True,
                  'gpu_accelerated': True,
                  'input_shape': (3, 224, 224),
                  'output_shape': (1000,)
              }

          def add_sensor(self, sensor_config: Dict[str, Any]):
              """Add a sensor to the perception system"""
              sensor = {
                  'type': sensor_config.get('type'),
                  'topic': sensor_config.get('topic'),
                  'enabled': True
              }
              self.sensors.append(sensor)
              logger.info(f"Added sensor: {sensor_config.get('type')} on {sensor_config.get('topic')}")

          def update(self):
              """Update perception processing"""
              if not self.running:
                  return

              # Process sensor data
              for sensor in self.sensors:
                  if sensor['enabled']:
                      sensor_data = self.get_sensor_data(sensor['topic'])
                      if sensor_data is not None:
                          results = self.process_sensor_data(sensor_data)
                          self.detection_results.extend(results)

          def get_sensor_data(self, topic: str):
              """Get sensor data from topic (simulated)"""
              # In real Isaac, this would connect to actual sensor topics
              # For simulation, return dummy data
              return {
                  'timestamp': time.time(),
                  'data': np.random.rand(480, 640, 3),
                  'topic': topic
              }

          def process_sensor_data(self, sensor_data):
              """Process sensor data through perception pipeline"""
              # Simulate GPU-accelerated processing
              results = []

              # Example: Object detection simulation
              num_detections = np.random.poisson(3)  # Random number of detections
              for i in range(num_detections):
                  detection = {
                      'id': f'detection_{i}',
                      'class': 'object',
                      'confidence': np.random.uniform(0.6, 0.99),
                      'bbox': [
                          np.random.uniform(0, 640),  # x
                          np.random.uniform(0, 480),  # y
                          np.random.uniform(20, 100), # width
                          np.random.uniform(20, 100)  # height
                      ],
                      'timestamp': sensor_data['timestamp']
                  }
                  results.append(detection)

              return results

      class IsaacNavigationComponent(IsaacAppComponent):
          """Navigation component for Isaac Apps"""
          def __init__(self, name: str, config: Dict[str, Any]):
              super().__init__(name, config)
              self.current_pose = np.array([0.0, 0.0, 0.0])  # x, y, theta
              self.current_velocity = np.array([0.0, 0.0])   # linear, angular
              self.goal_pose = np.array([0.0, 0.0, 0.0])
              self.path = []
              self.path_index = 0
              self.navigation_active = False

          def initialize(self):
              """Initialize navigation component"""
              super().initialize()

              # Initialize navigation parameters
              self.max_linear_vel = self.config.get('max_linear_vel', 0.5)
              self.max_angular_vel = self.config.get('max_angular_vel', 1.0)
              self.arrival_threshold = self.config.get('arrival_threshold', 0.1)

          def set_goal(self, x: float, y: float, theta: float = 0.0):
              """Set navigation goal"""
              self.goal_pose = np.array([x, y, theta])
              self.navigation_active = True
              self.plan_path()
              logger.info(f"Navigation goal set: ({x}, {y}, {theta})")

          def plan_path(self):
              """Plan path to goal (simplified)"""
              # In Isaac, this would use GPU-accelerated path planners
              # For simulation, create a straight line path
              steps = 20
              self.path = []

              for i in range(steps + 1):
                  t = i / steps
                  x = self.current_pose[0] + t * (self.goal_pose[0] - self.current_pose[0])
                  y = self.current_pose[1] + t * (self.goal_pose[1] - self.current_pose[1])
                  theta = self.current_pose[2] + t * (self.goal_pose[2] - self.current_pose[2])
                  self.path.append(np.array([x, y, theta]))

              self.path_index = 0
              logger.info(f"Path planned with {len(self.path)} waypoints")

          def update(self):
              """Update navigation logic"""
              if not self.running or not self.navigation_active:
                  return

              if self.path and self.path_index < len(self.path):
                  # Get next waypoint
                  target_pose = self.path[self.path_index]

                  # Calculate required movement
                  dx = target_pose[0] - self.current_pose[0]
                  dy = target_pose[1] - self.current_pose[1]
                  distance = np.sqrt(dx*dx + dy*dy)

                  if distance < self.arrival_threshold:
                      # Reached current waypoint, move to next
                      self.path_index += 1
                      if self.path_index >= len(self.path):
                          # Reached final goal
                          self.navigation_active = False
                          logger.info("Navigation goal reached!")
                          return

                      # Get new target
                      target_pose = self.path[self.path_index]
                      dx = target_pose[0] - self.current_pose[0]
                      dy = target_pose[1] - self.current_pose[1]
                      distance = np.sqrt(dx*dx + dy*dy)

                  # Calculate velocities
                  linear_vel = min(distance * 0.5, self.max_linear_vel)

                  # Calculate angular error
                  target_angle = np.arctan2(dy, dx)
                  angle_diff = target_angle - self.current_pose[2]

                  # Normalize angle
                  while angle_diff > np.pi:
                      angle_diff -= 2 * np.pi
                  while angle_diff < -np.pi:
                      angle_diff += 2 * np.pi

                  angular_vel = max(min(angle_diff * 2.0, self.max_angular_vel), -self.max_angular_vel)

                  # Set velocity command
                  self.current_velocity = np.array([linear_vel, angular_vel])

                  # Update pose (simplified - in real system, this comes from odometry)
                  dt = 0.1  # 10Hz update
                  self.current_pose[0] += linear_vel * np.cos(self.current_pose[2]) * dt
                  self.current_pose[1] += linear_vel * np.sin(self.current_pose[2]) * dt
                  self.current_pose[2] += angular_vel * dt

                  # Normalize orientation
                  while self.current_pose[2] > np.pi:
                      self.current_pose[2] -= 2 * np.pi
                  while self.current_pose[2] < -np.pi:
                      self.current_pose[2] += 2 * np.pi

          def get_command(self):
              """Get current velocity command"""
              if self.navigation_active and self.path:
                  return {
                      'linear': float(self.current_velocity[0]),
                      'angular': float(self.current_velocity[1]),
                      'active': self.navigation_active
                  }
              else:
                  return {'linear': 0.0, 'angular': 0.0, 'active': False}

      class IsaacManipulationComponent(IsaacAppComponent):
          """Manipulation component for Isaac Apps"""
          def __init__(self, name: str, config: Dict[str, Any]):
              super().__init__(name, config)
              self.joint_positions = {}
              self.joint_velocities = {}
              self.end_effector_pose = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # x, y, z, roll, pitch, yaw
              self.gripper_state = 'open'  # 'open', 'closed', 'moving'
              self.ik_solver = None

          def initialize(self):
              """Initialize manipulation component"""
              super().initialize()

              # Initialize joint positions
              joint_names = self.config.get('joint_names', [])
              for joint_name in joint_names:
                  self.joint_positions[joint_name] = 0.0
                  self.joint_velocities[joint_name] = 0.0

              # Initialize IK solver
              self.setup_ik_solver()

          def setup_ik_solver(self):
              """Setup inverse kinematics solver (simplified)"""
              logger.info("Setting up inverse kinematics solver")
              # In Isaac, this would use GPU-accelerated IK solvers
              self.ik_solver = {
                  'initialized': True,
                  'gpu_accelerated': True,
                  'solver_type': 'gpu_ik_solver'
              }

          def move_to_pose(self, position, orientation):
              """Move end effector to specified pose"""
              target_pose = np.array(position + orientation)  # [x,y,z,r,p,y]

              # Calculate inverse kinematics (simplified)
              joint_angles = self.calculate_ik(target_pose)

              if joint_angles is not None:
                  # Update joint positions
                  joint_names = list(self.joint_positions.keys())
                  for i, joint_name in enumerate(joint_names):
                      if i < len(joint_angles):
                          self.joint_positions[joint_name] = joint_angles[i]

                  logger.info(f"Moving to pose: {position}, orientation: {orientation}")
                  return True
              else:
                  logger.error("Failed to calculate IK solution")
                  return False

          def calculate_ik(self, target_pose):
              """Calculate inverse kinematics (simplified implementation)"""
              # In Isaac, this would use GPU-accelerated IK solvers
              # For simulation, return random valid joint angles
              num_joints = len(self.joint_positions)
              return [np.random.uniform(-np.pi, np.pi) for _ in range(num_joints)]

          def grasp_object(self):
              """Execute grasp action"""
              if self.gripper_state == 'open':
                  self.gripper_state = 'closing'
                  logger.info("Closing gripper to grasp object")
                  # Simulate grasp completion
                  time.sleep(0.5)
                  self.gripper_state = 'closed'
                  logger.info("Object grasped successfully")

          def release_object(self):
              """Release grasped object"""
              if self.gripper_state == 'closed':
                  self.gripper_state = 'opening'
                  logger.info("Opening gripper to release object")
                  # Simulate release completion
                  time.sleep(0.5)
                  self.gripper_state = 'open'
                  logger.info("Object released successfully")

      class IsaacAppManager:
          """Manager for Isaac Apps"""
          def __init__(self, config: IsaacAppConfig):
              self.config = config
              self.components = {}
              self.running = False
              self.update_thread = None

          def add_component(self, component: IsaacAppComponent):
              """Add a component to the app"""
              self.components[component.name] = component
              logger.info(f"Added component: {component.name}")

          def initialize(self):
              """Initialize all components"""
              logger.info(f"Initializing Isaac App: {self.config.app_name}")

              for name, component in self.components.items():
                  component.initialize()

          def start(self):
              """Start the Isaac App"""
              if not self.running:
                  self.initialize()

                  for name, component in self.components.items():
                      component.start()

                  self.running = True
                  self.update_thread = threading.Thread(target=self._update_loop)
                  self.update_thread.start()

                  logger.info(f"Isaac App started: {self.config.app_name}")

          def stop(self):
              """Stop the Isaac App"""
              if self.running:
                  self.running = False

                  if self.update_thread:
                      self.update_thread.join()

                  for name, component in self.components.items():
                      component.stop()

                  logger.info(f"Isaac App stopped: {self.config.app_name}")

          def _update_loop(self):
              """Main update loop for the app"""
              while self.running:
                  for name, component in self.components.items():
                      component.update()

                  time.sleep(0.1)  # 10Hz update rate

          def get_status(self):
              """Get status of all components"""
              status = {
                  'app_name': self.config.app_name,
                  'running': self.running,
                  'components': {}
              }

              for name, component in self.components.items():
                  status['components'][name] = component.get_status()

              return status

      def create_robotic_manipulation_app():
          """Create a sample robotic manipulation Isaac App"""
          config = IsaacAppConfig(
              app_name="RoboticManipulationApp",
              app_version="1.0.0",
              components=["perception", "navigation", "manipulation"],
              parameters={
                  "robot_name": "ur5",
                  "workspace_bounds": [-1.0, 1.0, -1.0, 1.0, 0.1, 1.0],
                  "gripper_type": "robotiq_2f_85"
              },
              dependencies=["isaac_ros", "isaac_sim"],
              gpu_required=True
          )

          # Create app manager
          app_manager = IsaacAppManager(config)

          # Create components
          perception_config = {
              'model_paths': ['/models/object_detection.pt'],
              'sensors': [
                  {'type': 'camera', 'topic': '/camera/rgb/image_rect_color'},
                  {'type': 'depth', 'topic': '/camera/depth/image_rect_raw'}
              ]
          }
          perception_comp = IsaacPerceptionComponent("perception", perception_config)

          navigation_config = {
              'max_linear_vel': 0.3,
              'max_angular_vel': 0.5,
              'arrival_threshold': 0.05
          }
          navigation_comp = IsaacNavigationComponent("navigation", navigation_config)

          manipulation_config = {
              'joint_names': ['shoulder_pan_joint', 'shoulder_lift_joint',
                            'elbow_joint', 'wrist_1_joint', 'wrist_2_joint', 'wrist_3_joint']
          }
          manipulation_comp = IsaacManipulationComponent("manipulation", manipulation_config)

          # Add components to app
          app_manager.add_component(perception_comp)
          app_manager.add_component(navigation_comp)
          app_manager.add_component(manipulation_comp)

          return app_manager

      def main():
          """Main function demonstrating Isaac Apps Framework"""
          logger.info("Starting Isaac Apps Framework Demo...")

          # Create robotic manipulation app
          app_manager = create_robotic_manipulation_app()

          # Start the app
          app_manager.start()

          # Simulate app operation
          time.sleep(2)

          # Get status
          status = app_manager.get_status()
          logger.info(f"App status: {json.dumps(status, indent=2, default=str)}")

          # Simulate some operations
          navigation_comp = app_manager.components.get('navigation')
          if navigation_comp:
              navigation_comp.set_goal(1.0, 1.0, 0.0)

          manipulation_comp = app_manager.components.get('manipulation')
          if manipulation_comp:
              manipulation_comp.move_to_pose([0.5, 0.0, 0.3], [0, 0, 0])
              manipulation_comp.grasp_object()

          # Run for a while
          time.sleep(5)

          # Stop the app
          app_manager.stop()
          logger.info("Isaac Apps Framework Demo completed.")

      if __name__ == "__main__":
          main()

practical_examples:
  -
    title: "Isaac Perception Pipeline Development"
    description: "Students develop a complete perception pipeline using Isaac SDK with GPU-accelerated object detection."
    objectives:
      - "Implement Isaac message handling for sensor data"
      - "Create GPU-accelerated object detection pipeline"
      - "Integrate multiple sensor modalities"
      - "Optimize pipeline for real-time performance"
    required_components:
      - "NVIDIA GPU with CUDA support"
      - "Isaac SDK installation"
      - "Camera and LIDAR sensors"
      - "Pre-trained detection models"
      - "Calibration tools"
    evaluation_criteria:
      - "Detection accuracy and speed"
      - "GPU utilization efficiency"
      - "Integration quality"
      - "Real-time performance"
  -
    title: "Isaac Navigation App Development"
    description: "Students create a complete navigation application using Isaac Apps framework with GPU-accelerated planning."
    objectives:
      - "Build modular navigation application"
      - "Implement GPU-accelerated path planning"
      - "Integrate perception and navigation"
      - "Test in simulation and real environments"
    required_components:
      - "Mobile robot platform"
      - "Navigation sensors (LIDAR, IMU)"
      - "Isaac Navigation stack"
      - "Mapping tools"
      - "Path planning algorithms"
    evaluation_criteria:
      - "Navigation success rate"
      - "Path optimization quality"
      - "System modularity"
      - "Performance in real-world testing"
  -
    title: "Isaac Manipulation Extension"
    description: "Students develop custom Isaac extension for robotic manipulation with GPU-accelerated grasp planning."
    objectives:
      - "Create custom Isaac extension"
      - "Implement GPU-accelerated grasp planning"
      - "Integrate with perception system"
      - "Validate grasp success rate"
    required_components:
      - "Robotic manipulator"
      - "3D perception sensors"
      - "End-effector/gripper"
      - "Grasp planning algorithms"
      - "Simulation environment"
    evaluation_criteria:
      - "Grasp planning accuracy"
      - "Extension functionality"
      - "GPU acceleration benefits"
      - "Integration with other systems"

summary: "Chapter 12 explored the NVIDIA Isaac SDK and APIs, covering Isaac's extension framework, message handling system, and Apps framework. Students learned to create custom components, implement GPU-accelerated processing pipelines, and build modular robotics applications. The chapter emphasized Isaac's software architecture and how to leverage its full capabilities for developing sophisticated robotics systems."

quiz:
  -
    question: "What is the primary purpose of Isaac Extensions?"
    options:
      - A: To reduce hardware requirements
      - B: To create custom components and plugins for Isaac applications
      - C: To eliminate the need for programming
      - D: To simplify sensor hardware
    correct_answer: "B"
    explanation: "Isaac Extensions allow developers to create custom components and plugins that extend Isaac's functionality."
  -
    question: "What does the Isaac Apps framework provide?"
    options:
      - A: Only simulation capabilities
      - B: Modular architecture for building robotics applications
      - C: Hardware components only
      - D: Communication protocols only
    correct_answer: "B"
    explanation: "The Isaac Apps framework provides a modular architecture for building comprehensive robotics applications."
  -
    question: "Why are GPU-accelerated libraries important in Isaac?"
    options:
      - A: They reduce memory requirements
      - B: They enable high-performance processing for AI and perception
      - C: They eliminate the need for sensors
      - D: They make robots physically stronger
    correct_answer: "B"
    explanation: "GPU-accelerated libraries enable high-performance processing for AI and perception tasks that would be too slow on CPUs."
  -
    question: "What is the role of Isaac Messages?"
    options:
      - A: To store robot hardware
      - B: To handle communication and data exchange between components
      - C: To control robot movement only
      - D: To manage power consumption
    correct_answer: "B"
    explanation: "Isaac Messages handle communication and data exchange between different components in the Isaac system."
  -
    question: "What is a key benefit of the modular architecture in Isaac Apps?"
    options:
      - A: Increased hardware costs
      - B: Reusability and easier maintenance of components
      - C: Reduced computing power
      - D: Simpler sensors
    correct_answer: "B"
    explanation: "The modular architecture enables reusability and easier maintenance of components in Isaac applications."

module_learning_outcomes:
  - "Implement GPU-accelerated robotics systems"
  - "Integrate AI perception and navigation capabilities"
  - "Develop simulation-to-reality pipelines"
  - "Optimize robot performance using NVIDIA platforms"

prerequisites:
  - "Basic understanding of Python programming"
  - "Fundamentals of linear algebra and calculus"
  - "Basic knowledge of robotics concepts"
  - "Introduction to machine learning concepts"
  - "Completion of Module 0 (Introduction and Foundations)"
  - "Completion of Chapter 01 (Physical AI Basics)"
  - "Completion of Chapter 03 (ROS2 Nodes, Topics & Services)"
  - "Completion of Chapter 11 (Introduction to NVIDIA Isaac)"

estimated_duration: "5 hours"
...
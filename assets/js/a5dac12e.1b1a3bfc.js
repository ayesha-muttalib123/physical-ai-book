"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[535],{6161:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>t,contentTitle:()=>l,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"08-Chapter-4-Gazebo-Simulation-Basics","title":"Chapter 4: Gazebo Simulation Basics","description":"Overview","source":"@site/docusaurus/docs/08-Chapter-4-Gazebo-Simulation-Basics.md","sourceDirName":".","slug":"/08-Chapter-4-Gazebo-Simulation-Basics","permalink":"/physical-ai-book/docs/08-Chapter-4-Gazebo-Simulation-Basics","draft":false,"unlisted":false,"editUrl":"https://github.com/ayesha-muttalib123/physical-ai-book/tree/main/docusaurus/docs/08-Chapter-4-Gazebo-Simulation-Basics.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"08-Chapter-4-Gazebo-Simulation-Basics","title":"Chapter 4: Gazebo Simulation Basics","sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Introduction To Digital Twins","permalink":"/physical-ai-book/docs/07-Chapter-3-Introduction-To-Digital-Twins"},"next":{"title":"Chapter 1: Integrating Unity For Visualization","permalink":"/physical-ai-book/docs/09-Chapter-1-Integrating-Unity-For-Visualization"}}');var o=r(4848),s=r(8453);const a={id:"08-Chapter-4-Gazebo-Simulation-Basics",title:"Chapter 4: Gazebo Simulation Basics",sidebar_position:8},l="Chapter 4: Gazebo Simulation Basics",t={},c=[{value:"Overview",id:"overview",level:2},{value:"Why It Matters",id:"why-it-matters",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Gazebo Architecture",id:"gazebo-architecture",level:3},{value:"URDF (Unified Robot Description Format)",id:"urdf-unified-robot-description-format",level:3},{value:"SDF (Simulation Description Format)",id:"sdf-simulation-description-format",level:3},{value:"Physics Engine",id:"physics-engine",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:3},{value:"Actuator Models",id:"actuator-models",level:3},{value:"Plugin System",id:"plugin-system",level:3},{value:"ROS2 Integration",id:"ros2-integration",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Advanced Robot Model with Multiple Sensors",id:"advanced-robot-model-with-multiple-sensors",level:3},{value:"Gazebo World with Complex Environment",id:"gazebo-world-with-complex-environment",level:3},{value:"ROS2 Node for Controlling Gazebo Robot",id:"ros2-node-for-controlling-gazebo-robot",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Maze Navigation in Gazebo",id:"maze-navigation-in-gazebo",level:3},{value:"Multi-Robot Simulation",id:"multi-robot-simulation",level:3},{value:"Sensor Validation Simulation",id:"sensor-validation-simulation",level:3},{value:"Summary",id:"summary",level:2},{value:"Quiz",id:"quiz",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Estimated Duration",id:"estimated-duration",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-4-gazebo-simulation-basics",children:"Chapter 4: Gazebo Simulation Basics"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"This chapter provides a comprehensive introduction to Gazebo simulation environment, covering the fundamental concepts needed to create and run robotic simulations. Students will learn about Gazebo's architecture, how to create robot models using URDF, design simulation environments, and integrate with ROS2. The chapter includes hands-on exercises to build basic simulations and understand the physics engine that powers realistic robot interactions."}),"\n",(0,o.jsx)(e.h2,{id:"why-it-matters",children:"Why It Matters"}),"\n",(0,o.jsx)(e.p,{children:"Gazebo is a critical tool in the robotics development pipeline, providing a realistic physics simulation environment that enables safe testing of robotic algorithms before deployment to real hardware. Understanding Gazebo basics is essential for creating effective digital twins, testing navigation algorithms, validating sensor models, and training AI systems. It allows developers to experiment with complex scenarios without the risks and costs associated with physical robots."}),"\n",(0,o.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-architecture",children:"Gazebo Architecture"}),"\n",(0,o.jsx)(e.p,{children:"Understanding the simulation server, GUI, and plugin system. Gazebo consists of a physics server that handles the simulation, a graphical user interface for visualization and interaction, and a plugin system that extends functionality."}),"\n",(0,o.jsx)(e.h3,{id:"urdf-unified-robot-description-format",children:"URDF (Unified Robot Description Format)"}),"\n",(0,o.jsx)(e.p,{children:"Defining robot geometry, kinematics, and dynamics. URDF is an XML format used to describe robot models, including links, joints, visual and collision properties, and inertial parameters."}),"\n",(0,o.jsx)(e.h3,{id:"sdf-simulation-description-format",children:"SDF (Simulation Description Format)"}),"\n",(0,o.jsx)(e.p,{children:"Describing simulation worlds and objects. SDF is an XML format used to describe simulation environments, including world properties, models, lighting, and physics settings."}),"\n",(0,o.jsx)(e.h3,{id:"physics-engine",children:"Physics Engine"}),"\n",(0,o.jsx)(e.p,{children:"Understanding how Gazebo simulates real-world physics. Gazebo uses physics engines like ODE, Bullet, or DART to simulate forces, collisions, friction, and other physical phenomena."}),"\n",(0,o.jsx)(e.h3,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Modeling cameras, LIDAR, IMU, and other sensors. Gazebo provides realistic simulation of various sensors with noise models and parameters that match real-world sensors."}),"\n",(0,o.jsx)(e.h3,{id:"actuator-models",children:"Actuator Models"}),"\n",(0,o.jsx)(e.p,{children:"Simulating robot joints and motors. Gazebo simulates the behavior of different types of joints and actuators, including their physical properties and control interfaces."}),"\n",(0,o.jsx)(e.h3,{id:"plugin-system",children:"Plugin System"}),"\n",(0,o.jsx)(e.p,{children:"Extending Gazebo functionality with custom code. Plugins allow developers to add custom behaviors, sensors, or controllers to the simulation environment."}),"\n",(0,o.jsx)(e.h3,{id:"ros2-integration",children:"ROS2 Integration"}),"\n",(0,o.jsx)(e.p,{children:"Connecting Gazebo with ROS2 for robot control. Gazebo can be integrated with ROS2 using Gazebo ROS packages to provide standard ROS2 interfaces for robot control and sensor data."}),"\n",(0,o.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,o.jsx)(e.h3,{id:"advanced-robot-model-with-multiple-sensors",children:"Advanced Robot Model with Multiple Sensors"}),"\n",(0,o.jsx)(e.p,{children:"Complete URDF model of a robot with camera, LIDAR, and IMU sensors:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0" ?>\r\n<robot name="advanced_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\r\n  \x3c!-- Base link --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <mesh filename="package://advanced_robot_description/meshes/base.dae"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <cylinder length="0.15" radius="0.25"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="10.0"/>\r\n      <inertia ixx="0.4" ixy="0.0" ixz="0.0" iyy="0.4" iyz="0.0" izz="0.2"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Inertial unit --\x3e\r\n  <joint name="imu_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="imu_link"/>\r\n    <origin xyz="0 0 0.05" rpy="0 0 0"/>\r\n  </joint>\r\n  <link name="imu_link">\r\n    <inertial>\r\n      <mass value="0.01"/>\r\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0001"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Camera --\x3e\r\n  <joint name="camera_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="camera_link"/>\r\n    <origin xyz="0.2 0 0.1" rpy="0 0 0"/>\r\n  </joint>\r\n  <link name="camera_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.02 0.05 0.03"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.02 0.05 0.03"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.1"/>\r\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0001"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- LIDAR --\x3e\r\n  <joint name="lidar_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="lidar_link"/>\r\n    <origin xyz="0.15 0 0.2" rpy="0 0 0"/>\r\n  </joint>\r\n  <link name="lidar_link">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.05" length="0.05"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <cylinder radius="0.05" length="0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.2"/>\r\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0002"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Wheels --\x3e\r\n  <joint name="wheel_left_joint" type="continuous">\r\n    <parent link="base_link"/>\r\n    <child link="wheel_left_link"/>\r\n    <origin xyz="0 0.25 -0.1" rpy="-1.5707 0 0"/>\r\n    <axis xyz="0 0 1"/>\r\n  </joint>\r\n  <link name="wheel_left_link">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.1" length="0.05"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <cylinder radius="0.1" length="0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="1.0"/>\r\n      <inertia ixx="0.005" ixy="0" ixz="0" iyy="0.005" iyz="0" izz="0.01"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="wheel_right_joint" type="continuous">\r\n    <parent link="base_link"/>\r\n    <child link="wheel_right_link"/>\r\n    <origin xyz="0 -0.25 -0.1" rpy="-1.5707 0 0"/>\r\n    <axis xyz="0 0 1"/>\r\n  </joint>\r\n  <link name="wheel_right_link">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.1" length="0.05"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <cylinder radius="0.1" length="0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="1.0"/>\r\n      <inertia ixx="0.005" ixy="0" ixz="0" iyy="0.005" iyz="0" izz="0.01"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Gazebo plugins --\x3e\r\n  <gazebo>\r\n    <plugin name="diff_drive" filename="libgazebo_ros_diff_drive.so">\r\n      <ros>\r\n        <namespace>robot</namespace>\r\n        <remapping>cmd_vel:=cmd_vel</remapping>\r\n        <remapping>odom:=odom</remapping>\r\n      </ros>\r\n      <update_rate>30</update_rate>\r\n      <left_joint>wheel_left_joint</left_joint>\r\n      <right_joint>wheel_right_joint</right_joint>\r\n      <wheel_separation>0.5</wheel_separation>\r\n      <wheel_diameter>0.2</wheel_diameter>\r\n      <max_wheel_torque>20</max_wheel_torque>\r\n      <max_wheel_acceleration>1.0</max_wheel_acceleration>\r\n      <publish_odom>true</publish_odom>\r\n      <publish_odom_tf>true</publish_odom_tf>\r\n      <publish_wheel_tf>true</publish_wheel_tf>\r\n      <odometry_frame>odom</odometry_frame>\r\n      <robot_base_frame>base_link</robot_base_frame>\r\n    </plugin>\r\n  </gazebo>\r\n\r\n  <gazebo reference="imu_link">\r\n    <sensor name="imu_sensor" type="imu">\r\n      <always_on>true</always_on>\r\n      <update_rate>100</update_rate>\r\n      <visualize>false</visualize>\r\n      <imu>\r\n        <angular_velocity>\r\n          <x>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>2e-4</stddev>\r\n            </noise>\r\n          </x>\r\n          <y>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>2e-4</stddev>\r\n            </noise>\r\n          </y>\r\n          <z>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>2e-4</stddev>\r\n            </noise>\r\n          </z>\r\n        </angular_velocity>\r\n        <linear_acceleration>\r\n          <x>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>1.7e-2</stddev>\r\n            </noise>\r\n          </x>\r\n          <y>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>1.7e-2</stddev>\r\n            </noise>\r\n          </y>\r\n          <z>\r\n            <noise type="gaussian">\r\n              <mean>0.0</mean>\r\n              <stddev>1.7e-2</stddev>\r\n            </noise>\r\n          </z>\r\n        </linear_acceleration>\r\n      </imu>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n  <gazebo reference="camera_link">\r\n    <sensor name="camera_sensor" type="camera">\r\n      <always_on>true</always_on>\r\n      <update_rate>30</update_rate>\r\n      <camera>\r\n        <horizontal_fov>1.047</horizontal_fov>\r\n        <image>\r\n          <width>640</width>\r\n          <height>480</height>\r\n          <format>R8G8B8</format>\r\n        </image>\r\n        <clip>\r\n          <near>0.1</near>\r\n          <far>10</far>\r\n        </clip>\r\n      </camera>\r\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\r\n        <ros>\r\n          <namespace>camera</namespace>\r\n          <remapping>image_raw:=image_raw</remapping>\r\n          <remapping>camera_info:=camera_info</remapping>\r\n        </ros>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n  <gazebo reference="lidar_link">\r\n    <sensor name="lidar_sensor" type="ray">\r\n      <always_on>true</always_on>\r\n      <update_rate>10</update_rate>\r\n      <ray>\r\n        <scan>\r\n          <horizontal>\r\n            <samples>360</samples>\r\n            <resolution>1</resolution>\r\n            <min_angle>-3.14159</min_angle>\r\n            <max_angle>3.14159</max_angle>\r\n          </horizontal>\r\n        </scan>\r\n        <range>\r\n          <min>0.1</min>\r\n          <max>10.0</max>\r\n          <resolution>0.01</resolution>\r\n        </range>\r\n      </ray>\r\n      <plugin name="lidar_controller" filename="libgazebo_ros_ray_sensor.so">\r\n        <ros>\r\n          <namespace>lidar</namespace>\r\n          <remapping>scan:=scan</remapping>\r\n        </ros>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n</robot>\n'})}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-world-with-complex-environment",children:"Gazebo World with Complex Environment"}),"\n",(0,o.jsx)(e.p,{children:"Advanced world file with multiple objects, lighting, and terrain:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0" ?>\r\n<sdf version="1.7">\r\n  <world name="complex_world">\r\n    \x3c!-- Physics configuration --\x3e\r\n    <physics type="ode">\r\n      <max_step_size>0.001</max_step_size>\r\n      <real_time_factor>1</real_time_factor>\r\n      <real_time_update_rate>1000</real_time_update_rate>\r\n      <gravity>0 0 -9.8</gravity>\r\n    </physics>\r\n\r\n    \x3c!-- Include ground plane --\x3e\r\n    <include>\r\n      <uri>model://ground_plane</uri>\r\n    </include>\r\n\r\n    \x3c!-- Include sun --\x3e\r\n    <include>\r\n      <uri>model://sun</uri>\r\n    </include>\r\n\r\n    \x3c!-- Add a custom terrain --\x3e\r\n    <model name="terrain">\r\n      <static>true</static>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <heightmap>\r\n              <uri>model://my_terrain/heightmap.png</uri>\r\n              <size>20 20 2</size>\r\n            </heightmap>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <heightmap>\r\n              <uri>model://my_terrain/heightmap.png</uri>\r\n              <size>20 20 2</size>\r\n            </heightmap>\r\n          </geometry>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n\r\n    \x3c!-- Add furniture models --\x3e\r\n    <include>\r\n      <uri>model://table</uri>\r\n      <pose>5 0 0 0 0 0</pose>\r\n    </include>\r\n\r\n    <include>\r\n      <uri>model://cylinder</uri>\r\n      <pose>-3 2 0.5 0 0 0</pose>\r\n    </include>\r\n\r\n    <include>\r\n      <uri>model://sphere</uri>\r\n      <pose>-3 -2 0.5 0 0 0</pose>\r\n    </include>\r\n\r\n    \x3c!-- Custom model definition --\x3e\r\n    <model name="obstacle_wall">\r\n      <pose>0 -5 0.5 0 0 0</pose>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <box>\r\n              <size>5 0.2 1</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <box>\r\n              <size>5 0.2 1</size>\r\n            </box>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.5 0.5 0.5 1</ambient>\r\n            <diffuse>0.8 0.8 0.8 1</diffuse>\r\n            <specular>0.1 0.1 0.1 1</specular>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n\r\n    \x3c!-- Custom model with different properties --\x3e\r\n    <model name="custom_obstacle">\r\n      <pose>3 3 0.3 0 0 0</pose>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <mesh>\r\n              <uri>model://custom_meshes/obstacle.dae</uri>\r\n            </mesh>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <mesh>\r\n              <uri>model://custom_meshes/obstacle.dae</uri>\r\n            </mesh>\r\n          </geometry>\r\n        </visual>\r\n        <inertial>\r\n          <mass>5.0</mass>\r\n          <inertia>\r\n            <ixx>0.4</ixx>\r\n            <ixy>0</ixy>\r\n            <ixz>0</ixz>\r\n            <iyy>0.4</iyy>\r\n            <iyz>0</iyz>\r\n            <izz>0.4</izz>\r\n          </inertial>\r\n        </inertial>\r\n      </link>\r\n    </model>\r\n\r\n    \x3c!-- Add atmospheric effects --\x3e\r\n    <atmosphere type="adiabatic">\r\n      <temperature>288.15</temperature>\r\n      <pressure>101325</pressure>\r\n    </atmosphere>\r\n\r\n    \x3c!-- Add magnetic field --\x3e\r\n    <magnetic_field>6e-06 2.3e-05 -4.2e-05</magnetic_field>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h3,{id:"ros2-node-for-controlling-gazebo-robot",children:"ROS2 Node for Controlling Gazebo Robot"}),"\n",(0,o.jsx)(e.p,{children:"Python node that sends commands to a robot in Gazebo simulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist\r\nfrom sensor_msgs.msg import LaserScan, Image\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport numpy as np\r\nimport math\r\n\r\nclass GazeboRobotController(Node):\r\n    def __init__(self):\r\n        super().__init__('gazebo_robot_controller')\r\n\r\n        # Create publisher for velocity commands\r\n        self.cmd_vel_publisher = self.create_publisher(Twist, '/robot/cmd_vel', 10)\r\n\r\n        # Create subscribers for sensor data\r\n        self.scan_subscription = self.create_subscription(\r\n            LaserScan, '/robot/lidar/scan', self.scan_callback, 10)\r\n        self.camera_subscription = self.create_subscription(\r\n            Image, '/robot/camera/image_raw', self.camera_callback, 10)\r\n\r\n        # Timer for control loop\r\n        self.control_timer = self.create_timer(0.1, self.control_loop)\r\n\r\n        # Initialize variables\r\n        self.scan_data = None\r\n        self.latest_image = None\r\n        self.cv_bridge = CvBridge()\r\n\r\n        # Robot state\r\n        self.linear_velocity = 0.0\r\n        self.angular_velocity = 0.0\r\n\r\n        self.get_logger().info('Gazebo robot controller initialized')\r\n\r\n    def scan_callback(self, msg):\r\n        self.scan_data = msg\r\n\r\n    def camera_callback(self, msg):\r\n        try:\r\n            self.latest_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\r\n        except Exception as e:\r\n            self.get_logger().error(f'Error converting image: {e}')\r\n\r\n    def control_loop(self):\r\n        if self.scan_data is None:\r\n            # If no scan data, send zero velocity\r\n            cmd_vel = Twist()\r\n            self.cmd_vel_publisher.publish(cmd_vel)\r\n            return\r\n\r\n        # Simple obstacle avoidance algorithm\r\n        cmd_vel = Twist()\r\n\r\n        # Check for obstacles in front\r\n        front_ranges = self.scan_data.ranges[150:210]  # Front 60 degrees\r\n        front_ranges = [r for r in front_ranges if not (r == float('inf') or r == float('nan'))]\r\n\r\n        if front_ranges:\r\n            min_front_dist = min(front_ranges)\r\n\r\n            if min_front_dist < 0.8:  # Obstacle within 0.8m\r\n                # Stop and turn\r\n                cmd_vel.linear.x = 0.0\r\n                cmd_vel.angular.z = 0.5  # Turn right\r\n                self.get_logger().warn(f'Obstacle detected: {min_front_dist:.2f}m')\r\n            else:\r\n                # Move forward with obstacle avoidance\r\n                cmd_vel.linear.x = 0.5\r\n\r\n                # Check left and right for better path\r\n                left_ranges = self.scan_data.ranges[210:270]\r\n                right_ranges = self.scan_data.ranges[90:150]\r\n\r\n                left_avg = np.mean([r for r in left_ranges if not (r == float('inf') or r == float('nan'))])\r\n                right_avg = np.mean([r for r in right_ranges if not (r == float('inf') or r == float('nan'))])\r\n\r\n                if left_avg > right_avg:\r\n                    cmd_vel.angular.z = 0.2  # Turn slightly right\r\n                elif right_avg > left_avg:\r\n                    cmd_vel.angular.z = -0.2  # Turn slightly left\r\n        else:\r\n            # No valid front ranges, stop\r\n            cmd_vel.linear.x = 0.0\r\n            cmd_vel.angular.z = 0.0\r\n\r\n        self.cmd_vel_publisher.publish(cmd_vel)\r\n\r\n        # Log current velocities\r\n        self.get_logger().info(f'Velocity: linear={cmd_vel.linear.x:.2f}, angular={cmd_vel.angular.z:.2f}')\r\n\r\n    def process_camera_data(self):\r\n        if self.latest_image is not None:\r\n            # Simple example: detect red objects in the image\r\n            hsv = cv2.cvtColor(self.latest_image, cv2.COLOR_BGR2HSV)\r\n\r\n            # Define range for red color\r\n            lower_red = np.array([0, 50, 50])\r\n            upper_red = np.array([10, 255, 255])\r\n            mask1 = cv2.inRange(hsv, lower_red, upper_red)\r\n\r\n            lower_red = np.array([170, 50, 50])\r\n            upper_red = np.array([180, 255, 255])\r\n            mask2 = cv2.inRange(hsv, lower_red, upper_red)\r\n\r\n            mask = mask1 + mask2\r\n\r\n            # Find contours\r\n            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n            if contours:\r\n                # Find the largest contour\r\n                largest_contour = max(contours, key=cv2.contourArea)\r\n                if cv2.contourArea(largest_contour) > 500:  # Only consider large enough objects\r\n                    # Calculate centroid\r\n                    M = cv2.moments(largest_contour)\r\n                    if M[\"m00\"] != 0:\r\n                        cx = int(M[\"m10\"] / M[\"m00\"])\r\n                        cy = int(M[\"m01\"] / M[\"m00\"])\r\n\r\n                        # Calculate horizontal position relative to image center\r\n                        img_center_x = self.latest_image.shape[1] / 2\r\n                        error_x = cx - img_center_x\r\n\r\n                        # Log detection\r\n                        self.get_logger().info(f'Red object detected at ({cx}, {cy}), error: {error_x}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    controller = GazeboRobotController()\r\n\r\n    try:\r\n        rclpy.spin(controller)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        controller.destroy_node()\r\n        rclpy.shutdown()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,o.jsx)(e.h3,{id:"maze-navigation-in-gazebo",children:"Maze Navigation in Gazebo"}),"\n",(0,o.jsx)(e.p,{children:"Students create a maze environment in Gazebo and implement navigation algorithms to guide a robot through it."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Objectives:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Design a maze environment in Gazebo"}),"\n",(0,o.jsx)(e.li,{children:"Implement navigation algorithms"}),"\n",(0,o.jsx)(e.li,{children:"Integrate sensor data for navigation"}),"\n",(0,o.jsx)(e.li,{children:"Test algorithms in simulation"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Required Components:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Gazebo simulation environment"}),"\n",(0,o.jsx)(e.li,{children:"Robot model with sensors"}),"\n",(0,o.jsx)(e.li,{children:"Navigation algorithms"}),"\n",(0,o.jsx)(e.li,{children:"Maze world design"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Evaluation Criteria:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Successful maze design"}),"\n",(0,o.jsx)(e.li,{children:"Effective navigation algorithm"}),"\n",(0,o.jsx)(e.li,{children:"Proper sensor integration"}),"\n",(0,o.jsx)(e.li,{children:"Successful maze completion"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"multi-robot-simulation",children:"Multi-Robot Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Students set up a simulation with multiple robots and implement coordination algorithms."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Objectives:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Create multiple robot models"}),"\n",(0,o.jsx)(e.li,{children:"Design shared environment"}),"\n",(0,o.jsx)(e.li,{children:"Implement coordination algorithms"}),"\n",(0,o.jsx)(e.li,{children:"Test multi-robot behaviors"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Required Components:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Multiple robot models"}),"\n",(0,o.jsx)(e.li,{children:"Shared simulation environment"}),"\n",(0,o.jsx)(e.li,{children:"Communication protocols"}),"\n",(0,o.jsx)(e.li,{children:"Coordination algorithms"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Evaluation Criteria:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Proper multi-robot setup"}),"\n",(0,o.jsx)(e.li,{children:"Effective coordination"}),"\n",(0,o.jsx)(e.li,{children:"Avoidance of conflicts"}),"\n",(0,o.jsx)(e.li,{children:"Successful task completion"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"sensor-validation-simulation",children:"Sensor Validation Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Students validate real robot sensors by comparing simulation data with real-world measurements."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Objectives:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Configure sensors in simulation"}),"\n",(0,o.jsx)(e.li,{children:"Collect real-world sensor data"}),"\n",(0,o.jsx)(e.li,{children:"Compare simulation vs real data"}),"\n",(0,o.jsx)(e.li,{children:"Analyze discrepancies"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Required Components:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Simulated sensor models"}),"\n",(0,o.jsx)(e.li,{children:"Real robot with sensors"}),"\n",(0,o.jsx)(e.li,{children:"Data collection tools"}),"\n",(0,o.jsx)(e.li,{children:"Analysis tools"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Evaluation Criteria:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Accurate sensor simulation"}),"\n",(0,o.jsx)(e.li,{children:"Comprehensive data collection"}),"\n",(0,o.jsx)(e.li,{children:"Thorough analysis"}),"\n",(0,o.jsx)(e.li,{children:"Actionable insights"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Chapter 7 covered the fundamentals of Gazebo simulation, including robot modeling with URDF, environment design with SDF, and integration with ROS2. Students learned about Gazebo's architecture, physics engine, and plugin system. Through practical examples, they gained hands-on experience with creating and controlling robots in simulation environments."}),"\n",(0,o.jsx)(e.h2,{id:"quiz",children:"Quiz"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"What does URDF stand for?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"A: Unified Robot Description Format"}),"\n",(0,o.jsx)(e.li,{children:"B: Universal Robot Design Framework"}),"\n",(0,o.jsx)(e.li,{children:"C: Unified Robotics Development Format"}),"\n",(0,o.jsx)(e.li,{children:"D: Universal Robot Description File"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Answer: A"})," - URDF stands for Unified Robot Description Format, which is used to describe robot geometry, kinematics, and dynamics."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"What does SDF stand for?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"A: Simulation Development Format"}),"\n",(0,o.jsx)(e.li,{children:"B: Simulation Description Format"}),"\n",(0,o.jsx)(e.li,{children:"C: System Design Framework"}),"\n",(0,o.jsx)(e.li,{children:"D: Sensor Definition Format"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Answer: B"})," - SDF stands for Simulation Description Format, which is used to describe simulation worlds and objects in Gazebo."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"What is the primary purpose of Gazebo plugins?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"A: To make Gazebo run faster"}),"\n",(0,o.jsx)(e.li,{children:"B: To extend Gazebo functionality with custom code"}),"\n",(0,o.jsx)(e.li,{children:"C: To reduce memory usage"}),"\n",(0,o.jsx)(e.li,{children:"D: To create 3D models"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Answer: B"})," - Gazebo plugins are used to extend Gazebo functionality with custom code, such as sensor models, controllers, and other extensions."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"Which physics engines can be used with Gazebo?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"A: Only ODE"}),"\n",(0,o.jsx)(e.li,{children:"B: ODE, Bullet, and DART"}),"\n",(0,o.jsx)(e.li,{children:"C: Only Bullet"}),"\n",(0,o.jsx)(e.li,{children:"D: Only DART"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Answer: B"})," - Gazebo supports multiple physics engines including ODE, Bullet, and DART."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsx)(e.p,{children:"What is the typical update rate for IMU sensors in Gazebo?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"A: 10 Hz"}),"\n",(0,o.jsx)(e.li,{children:"B: 50 Hz"}),"\n",(0,o.jsx)(e.li,{children:"C: 100 Hz"}),"\n",(0,o.jsx)(e.li,{children:"D: 1000 Hz"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Answer: C"})," - IMU sensors in Gazebo typically have an update rate of 100 Hz, which matches many real IMU sensors."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,o.jsx)(e.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Create simulation environments for robot testing"}),"\n",(0,o.jsx)(e.li,{children:"Implement physics-based simulations"}),"\n",(0,o.jsx)(e.li,{children:"Bridge simulation and reality"}),"\n",(0,o.jsx)(e.li,{children:"Validate robot behaviors in simulation"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Basic understanding of Python programming"}),"\n",(0,o.jsx)(e.li,{children:"Fundamentals of linear algebra and calculus"}),"\n",(0,o.jsx)(e.li,{children:"Basic knowledge of robotics concepts"}),"\n",(0,o.jsx)(e.li,{children:"Introduction to machine learning concepts"}),"\n",(0,o.jsx)(e.li,{children:"Completion of Module 0 (Introduction and Foundations)"}),"\n",(0,o.jsx)(e.li,{children:"Completion of Chapter 01 (Physical AI Basics)"}),"\n",(0,o.jsx)(e.li,{children:"Completion of Chapter 06 (Introduction to Digital Twins)"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"estimated-duration",children:"Estimated Duration"}),"\n",(0,o.jsx)(e.p,{children:"6 hours"})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>a,x:()=>l});var i=r(6540);const o={},s=i.createContext(o);function a(n){const e=i.useContext(s);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),i.createElement(s.Provider,{value:e},n.children)}}}]);
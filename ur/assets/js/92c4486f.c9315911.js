"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[739],{4239:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"21-humanoid-project-examples-capstone","title":"Humanoid Project Examples & Capstone","description":"Overview","source":"@site/docusaurus/docs/21-humanoid-project-examples-capstone.md","sourceDirName":".","slug":"/21-humanoid-project-examples-capstone","permalink":"/physical-ai-book/ur/docs/21-humanoid-project-examples-capstone","draft":false,"unlisted":false,"editUrl":"https://github.com/ayesha-muttalib123/physical-ai-book/tree/main/docusaurus/docs/21-humanoid-project-examples-capstone.md","tags":[],"version":"current","sidebarPosition":21,"frontMatter":{"id":"21-humanoid-project-examples-capstone","title":"Humanoid Project Examples & Capstone","sidebar_position":21},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Language-Action Integration","permalink":"/physical-ai-book/ur/docs/20-Chapter-4-Language-Action-Integration"}}');var s=r(4848),a=r(8453);const o={id:"21-humanoid-project-examples-capstone",title:"Humanoid Project Examples & Capstone",sidebar_position:21},i="Chapter 5: Humanoid Project Examples & Capstone",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Why It Matters",id:"why-it-matters",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"System Integration",id:"system-integration",level:3},{value:"Project Planning",id:"project-planning",level:3},{value:"Multi-Modal Fusion",id:"multi-modal-fusion",level:3},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:3},{value:"Real-World Deployment",id:"real-world-deployment",level:3},{value:"Performance Evaluation",id:"performance-evaluation",level:3},{value:"Safety Considerations",id:"safety-considerations",level:3},{value:"Scalability",id:"scalability",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Integrated Humanoid Assistant System",id:"integrated-humanoid-assistant-system",level:3},{value:"Humanoid Capstone Project Framework",id:"humanoid-capstone-project-framework",level:3},{value:"Humanoid Safety and Performance Monitoring",id:"humanoid-safety-and-performance-monitoring",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Humanoid Service Robot",id:"humanoid-service-robot",level:3},{value:"Humanoid Research Platform",id:"humanoid-research-platform",level:3},{value:"Humanoid Educational Assistant",id:"humanoid-educational-assistant",level:3},{value:"Summary",id:"summary",level:2},{value:"Quiz",id:"quiz",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Estimated Duration",id:"estimated-duration",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-5-humanoid-project-examples--capstone",children:"Chapter 5: Humanoid Project Examples & Capstone"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This capstone chapter brings together all the concepts learned throughout the Vision-Language-Action & Humanoids module. Students will work on comprehensive humanoid robot projects that integrate vision, language, and action capabilities. The chapter provides detailed project examples, implementation guidelines, and evaluation criteria for creating sophisticated humanoid robots that can perceive their environment, understand natural language commands, and execute complex tasks. Students will develop end-to-end systems that demonstrate the full potential of VLA-enabled humanoid robots."}),"\n",(0,s.jsx)(n.h2,{id:"why-it-matters",children:"Why It Matters"}),"\n",(0,s.jsx)(n.p,{children:"Capstone projects are essential for synthesizing knowledge from multiple domains and applying it to real-world challenges. This chapter provides students with the opportunity to integrate all the concepts learned about vision-language-action systems and humanoid control into comprehensive projects. These projects prepare students for advanced robotics research and development by requiring them to solve complex, multi-faceted problems that mirror real-world robotics applications."}),"\n",(0,s.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,s.jsx)(n.h3,{id:"system-integration",children:"System Integration"}),"\n",(0,s.jsx)(n.p,{children:"Combining vision, language, and action components. This involves bringing together different subsystems to create a unified, functional humanoid robot that can process inputs from multiple modalities and produce coordinated outputs."}),"\n",(0,s.jsx)(n.h3,{id:"project-planning",children:"Project Planning"}),"\n",(0,s.jsx)(n.p,{children:"Designing and managing complex robotics projects. This includes planning project phases, resource allocation, timeline management, and risk assessment for complex humanoid development projects."}),"\n",(0,s.jsx)(n.h3,{id:"multi-modal-fusion",children:"Multi-Modal Fusion"}),"\n",(0,s.jsx)(n.p,{children:"Integrating information from different sensory modalities. This involves combining data from vision, language, and other sensors to create a coherent understanding that enables appropriate action selection."}),"\n",(0,s.jsx)(n.h3,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,s.jsx)(n.p,{children:"Creating intuitive interfaces for human operators. This encompasses both the technical aspects of processing human commands and the design aspects of making interactions natural and effective."}),"\n",(0,s.jsx)(n.h3,{id:"real-world-deployment",children:"Real-World Deployment"}),"\n",(0,s.jsx)(n.p,{children:"Addressing challenges of deploying in actual environments. This includes considerations for robustness, safety, adaptation to changing conditions, and handling of unexpected situations."}),"\n",(0,s.jsx)(n.h3,{id:"performance-evaluation",children:"Performance Evaluation"}),"\n",(0,s.jsx)(n.p,{children:"Measuring success across multiple dimensions. This involves developing metrics and methodologies to assess the effectiveness of integrated humanoid systems across different tasks and scenarios."}),"\n",(0,s.jsx)(n.h3,{id:"safety-considerations",children:"Safety Considerations"}),"\n",(0,s.jsx)(n.p,{children:"Ensuring safe operation of humanoid robots. This encompasses safety mechanisms, emergency procedures, and fail-safe behaviors that protect both the robot and its environment."}),"\n",(0,s.jsx)(n.h3,{id:"scalability",children:"Scalability"}),"\n",(0,s.jsx)(n.p,{children:"Designing systems that can grow and adapt. This involves creating architectures that can accommodate additional capabilities, increased complexity, and evolving requirements."}),"\n",(0,s.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,s.jsx)(n.h3,{id:"integrated-humanoid-assistant-system",children:"Integrated Humanoid Assistant System"}),"\n",(0,s.jsx)(n.p,{children:"Complete integrated system combining VLA capabilities with humanoid control:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nIntegrated Humanoid Assistant System\r\nComplete system integrating vision, language, and action capabilities\r\n"""\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, JointState, Imu\r\nfrom geometry_msgs.msg import Twist, Pose, Point\r\nfrom std_msgs.msg import String, Bool, Float64\r\nfrom vision_msgs.msg import Detection2DArray\r\nfrom cv_bridge import CvBridge\r\nimport torch\r\nimport torch.nn as nn\r\nimport numpy as np\r\nimport spacy\r\nimport cv2\r\nimport math\r\nfrom typing import Dict, List, Tuple, Optional\r\nimport threading\r\nimport queue\r\nimport time\r\nimport uuid\r\n\r\nclass VisionSystem:\r\n    """Vision processing system for the humanoid robot"""\r\n    def __init__(self):\r\n        self.bridge = CvBridge()\r\n        self.object_detections = []\r\n        self.current_image = None\r\n        self.feature_points = []\r\n\r\n    def process_image(self, image_msg):\r\n        """Process incoming camera image"""\r\n        try:\r\n            cv_image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding=\'bgr8\')\r\n            self.current_image = cv_image\r\n\r\n            # Perform object detection (simplified - in real implementation, use actual detector)\r\n            self.object_detections = self.detect_objects(cv_image)\r\n\r\n            # Extract features for tracking\r\n            self.feature_points = self.extract_features(cv_image)\r\n\r\n            return True\r\n        except Exception as e:\r\n            print(f"Vision processing error: {e}")\r\n            return False\r\n\r\n    def detect_objects(self, image):\r\n        """Detect objects in the image (simplified implementation)"""\r\n        # In real implementation, this would use a trained object detection model\r\n        # For simulation, return some dummy detections\r\n        height, width = image.shape[:2]\r\n        detections = []\r\n\r\n        # Simulate some detections\r\n        for i in range(3):\r\n            detection = {\r\n                \'name\': f\'object_{i}\',\r\n                \'confidence\': np.random.uniform(0.7, 0.99),\r\n                \'bbox\': {\r\n                    \'x\': np.random.randint(0, width - 50),\r\n                    \'y\': np.random.randint(0, height - 50),\r\n                    \'width\': np.random.randint(30, 80),\r\n                    \'height\': np.random.randint(30, 80)\r\n                },\r\n                \'center\': (\r\n                    np.random.randint(0, width),\r\n                    np.random.randint(0, height)\r\n                )\r\n            }\r\n            detections.append(detection)\r\n\r\n        return detections\r\n\r\n    def extract_features(self, image):\r\n        """Extract visual features for tracking"""\r\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n        # Use ORB for feature extraction\r\n        orb = cv2.ORB_create(nfeatures=200)\r\n        keypoints, descriptors = orb.detectAndCompute(gray, None)\r\n        return {\'keypoints\': keypoints, \'descriptors\': descriptors}\r\n\r\nclass LanguageSystem:\r\n    """Natural language processing system"""\r\n    def __init__(self):\r\n        # Load spaCy model for NLP\r\n        try:\r\n            self.nlp = spacy.load("en_core_web_sm")\r\n        except OSError:\r\n            print("spaCy model not found. Install with: python -m spacy download en_core_web_sm")\r\n            self.nlp = None\r\n\r\n        # Define command vocabulary\r\n        self.action_keywords = {\r\n            \'move\': [\'go\', \'move\', \'walk\', \'navigate\', \'approach\'],\r\n            \'grasp\': [\'grasp\', \'grab\', \'pick up\', \'take\', \'hold\'],\r\n            \'place\': [\'place\', \'put\', \'set\', \'release\'],\r\n            \'look\': [\'look\', \'see\', \'find\', \'locate\', \'search\'],\r\n            \'turn\': [\'turn\', \'rotate\', \'face\', \'orient\'],\r\n            \'follow\': [\'follow\', \'accompany\', \'come with\']\r\n        }\r\n\r\n    def parse_command(self, command: str) -> Dict:\r\n        """Parse natural language command"""\r\n        if self.nlp is None:\r\n            return self.fallback_parse(command)\r\n\r\n        doc = self.nlp(command.lower())\r\n\r\n        # Extract action\r\n        action = self.extract_action(doc)\r\n\r\n        # Extract object\r\n        obj = self.extract_object(doc)\r\n\r\n        # Extract location/direction\r\n        location = self.extract_location(doc)\r\n\r\n        # Extract spatial relations\r\n        relation = self.extract_spatial_relation(doc)\r\n\r\n        return {\r\n            \'command\': command,\r\n            \'action\': action,\r\n            \'object\': obj,\r\n            \'location\': location,\r\n            \'relation\': relation,\r\n            \'entities\': [(ent.text, ent.label_) for ent in doc.ents]\r\n        }\r\n\r\n    def fallback_parse(self, command: str) -> Dict:\r\n        """Fallback parser if spaCy is not available"""\r\n        command_lower = command.lower()\r\n\r\n        # Simple keyword matching\r\n        action = None\r\n        for action_type, keywords in self.action_keywords.items():\r\n            for keyword in keywords:\r\n                if keyword in command_lower:\r\n                    action = action_type\r\n                    break\r\n            if action:\r\n                break\r\n\r\n        # Extract simple object mentions\r\n        obj = None\r\n        for category in self.object_categories:\r\n            if category in command_lower:\r\n                obj = category\r\n                break\r\n\r\n        # Extract spatial relations\r\n        relation = None\r\n        for relation_word in self.spatial_relations:\r\n            if relation_word in command_lower:\r\n                relation = relation_word\r\n                break\r\n\r\n        return {\r\n            \'command\': command,\r\n            \'action\': action,\r\n            \'object\': obj,\r\n            \'location\': None,\r\n            \'relation\': relation,\r\n            \'entities\': []\r\n        }\r\n\r\n    def extract_action(self, doc) -> Optional[str]:\r\n        """Extract action from parsed document"""\r\n        for token in doc:\r\n            if token.pos_ in [\'VERB\', \'AUX\'] and not token.is_stop:\r\n                for action_type, keywords in self.action_keywords.items():\r\n                    if any(keyword in [token.text, token.lemma_] for keyword in keywords):\r\n                        return action_type\r\n        return None\r\n\r\n    def extract_object(self, doc) -> Optional[str]:\r\n        """Extract object from parsed document"""\r\n        for token in doc:\r\n            if token.pos_ in [\'NOUN\', \'PROPN\']:\r\n                return token.text\r\n\r\n        # Look for compound nouns\r\n        for chunk in doc.noun_chunks:\r\n            if any(cat in chunk.text.lower() for cat in self.object_categories):\r\n                return chunk.text\r\n\r\n        return None\r\n\r\n    def extract_location(self, doc) -> Optional[str]:\r\n        """Extract location from parsed document"""\r\n        for ent in doc.ents:\r\n            if ent.label_ in [\'LOC\', \'GPE\', \'FAC\']:  # Location, GeoPolitical Entity, Facility\r\n                return ent.text\r\n        return None\r\n\r\n    def extract_spatial_relation(self, doc) -> Optional[str]:\r\n        """Extract spatial relation from parsed document"""\r\n        for token in doc:\r\n            if token.text in self.spatial_relations:\r\n                return token.text\r\n        return None\r\n\r\nclass ActionSystem:\r\n    """Action execution system for humanoid robot"""\r\n    def __init__(self):\r\n        self.current_pose = np.array([0.0, 0.0, 0.0])  # x, y, theta\r\n        self.holding_object = None\r\n        self.navigation_target = None\r\n        self.action_queue = queue.Queue()\r\n        self.is_moving = False\r\n\r\n    def execute_action(self, parsed_command: Dict):\r\n        """Execute action based on parsed command"""\r\n        action_type = parsed_command.get(\'action\')\r\n        obj = parsed_command.get(\'object\')\r\n        location = parsed_command.get(\'location\')\r\n\r\n        if action_type == \'move\':\r\n            return self.execute_move(location or obj)\r\n        elif action_type == \'grasp\':\r\n            return self.execute_grasp(obj)\r\n        elif action_type == \'place\':\r\n            return self.execute_place()\r\n        elif action_type == \'look\':\r\n            return self.execute_look(obj)\r\n        elif action_type == \'turn\':\r\n            return self.execute_turn(parsed_command.get(\'relation\'))\r\n        else:\r\n            print(f"Unknown action: {action_type}")\r\n            return False\r\n\r\n    def execute_move(self, target):\r\n        """Execute move action"""\r\n        print(f"Moving toward {target}")\r\n        # In real implementation, this would generate navigation commands\r\n        self.navigation_target = target\r\n        return True\r\n\r\n    def execute_grasp(self, obj):\r\n        """Execute grasp action"""\r\n        print(f"Grasping {obj}")\r\n        self.holding_object = obj\r\n        return True\r\n\r\n    def execute_place(self):\r\n        """Execute place action"""\r\n        if self.holding_object:\r\n            print(f"Placing {self.holding_object}")\r\n            self.holding_object = None\r\n            return True\r\n        return False\r\n\r\n    def execute_look(self, obj):\r\n        """Execute look action"""\r\n        print(f"Looking for {obj}")\r\n        return True\r\n\r\n    def execute_turn(self, direction):\r\n        """Execute turn action"""\r\n        print(f"Turning {direction or \'around\'}")\r\n        return True\r\n\r\nclass HumanoidController:\r\n    """High-level controller managing the humanoid robot"""\r\n    def __init__(self):\r\n        self.vision_system = VisionSystem()\r\n        self.language_system = LanguageSystem()\r\n        self.action_system = ActionSystem()\r\n        self.system_state = \'idle\'  # idle, processing, executing, error\r\n        self.safety_enabled = True\r\n\r\n    def process_command(self, command: str):\r\n        """Process a natural language command"""\r\n        print(f"Processing command: {command}")\r\n\r\n        # Parse command\r\n        parsed_command = self.language_system.parse_command(command)\r\n\r\n        # Execute action\r\n        success = self.action_system.execute_action(parsed_command)\r\n\r\n        if success:\r\n            self.system_state = \'executing\'\r\n            print(f"Command executed: {command}")\r\n        else:\r\n            self.system_state = \'error\'\r\n            print(f"Command failed: {command}")\r\n\r\n        return success\r\n\r\n    def update_vision(self, image_msg):\r\n        """Update vision system with new image"""\r\n        return self.vision_system.process_image(image_msg)\r\n\r\n    def get_system_status(self):\r\n        """Get current system status"""\r\n        return {\r\n            \'state\': self.system_state,\r\n            \'holding_object\': self.action_system.holding_object,\r\n            \'navigation_target\': self.action_system.navigation_target,\r\n            \'safety_enabled\': self.safety_enabled\r\n        }\r\n\r\nclass IntegratedHumanoidNode(Node):\r\n    """ROS2 node for the integrated humanoid system"""\r\n    def __init__(self):\r\n        super().__init__(\'integrated_humanoid_assistant\')\r\n\r\n        # Publishers and subscribers\r\n        self.image_sub = self.create_subscription(\r\n            Image, \'/camera/rgb/image_raw\', self.image_callback, 10)\r\n        self.command_sub = self.create_subscription(\r\n            String, \'/humanoid/command\', self.command_callback, 10)\r\n        self.joint_state_sub = self.create_subscription(\r\n            JointState, \'/joint_states\', self.joint_state_callback, 10)\r\n        self.imu_sub = self.create_subscription(\r\n            Imu, \'/imu/data\', self.imu_callback, 10)\r\n\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\r\n        self.status_pub = self.create_publisher(String, \'/humanoid/status\', 10)\r\n        self.detection_pub = self.create_publisher(Detection2DArray, \'/object_detections\', 10)\r\n\r\n        # Initialize integrated system\r\n        self.humanoid_controller = HumanoidController()\r\n        self.bridge = CvBridge()\r\n\r\n        # Threading for processing\r\n        self.processing_lock = threading.Lock()\r\n        self.command_queue = queue.Queue()\r\n\r\n        # Timer for system updates\r\n        self.system_timer = self.create_timer(0.1, self.system_update_callback)\r\n\r\n        self.get_logger().info(\'Integrated Humanoid Assistant initialized\')\r\n\r\n    def image_callback(self, msg):\r\n        """Process incoming camera image"""\r\n        with self.processing_lock:\r\n            success = self.humanoid_controller.update_vision(msg)\r\n            if not success:\r\n                self.get_logger().error(\'Vision processing failed\')\r\n\r\n    def command_callback(self, msg):\r\n        """Process incoming command"""\r\n        command = msg.data\r\n        self.get_logger().info(f\'Received command: {command}\')\r\n\r\n        # Add command to processing queue\r\n        self.command_queue.put(command)\r\n\r\n    def joint_state_callback(self, msg):\r\n        """Process joint state updates"""\r\n        # Update controller with joint information\r\n        pass\r\n\r\n    def imu_callback(self, msg):\r\n        """Process IMU data for balance"""\r\n        # Use IMU data for balance control\r\n        pass\r\n\r\n    def system_update_callback(self):\r\n        """Main system update loop"""\r\n        # Process any queued commands\r\n        while not self.command_queue.empty():\r\n            try:\r\n                command = self.command_queue.get_nowait()\r\n                success = self.humanoid_controller.process_command(command)\r\n\r\n                # Publish system status\r\n                status = self.humanoid_controller.get_system_status()\r\n                status_msg = String()\r\n                status_msg.data = str(status)\r\n                self.status_pub.publish(status_msg)\r\n\r\n            except queue.Empty:\r\n                break\r\n\r\n        # Publish system status periodically\r\n        status = self.humanoid_controller.get_system_status()\r\n        status_msg = String()\r\n        status_msg.data = str(status)\r\n        self.status_pub.publish(status_msg)\r\n\r\n    def publish_joint_commands(self, joint_positions: Dict[str, float]):\r\n        """Publish joint commands to robot"""\r\n        joint_state = JointState()\r\n        joint_state.header.stamp = self.get_clock().now().to_msg()\r\n        joint_state.header.frame_id = \'base_link\'\r\n\r\n        for name, position in joint_positions.items():\r\n            joint_state.name.append(name)\r\n            joint_state.position.append(position)\r\n            joint_state.velocity.append(0.0)\r\n            joint_state.effort.append(0.0)\r\n\r\n        self.joint_cmd_pub.publish(joint_state)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = IntegratedHumanoidNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down integrated humanoid assistant...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"humanoid-capstone-project-framework",children:"Humanoid Capstone Project Framework"}),"\n",(0,s.jsx)(n.p,{children:"Framework for implementing comprehensive humanoid capstone projects:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nHumanoid Capstone Project Framework\r\nFramework for implementing comprehensive humanoid capstone projects\r\n"""\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String, Bool, Float64\r\nfrom sensor_msgs.msg import Image, JointState\r\nfrom geometry_msgs.msg import Pose, Twist\r\nfrom action_msgs.msg import GoalStatus\r\nimport json\r\nimport threading\r\nimport time\r\nfrom typing import Dict, List, Callable, Any\r\nfrom dataclasses import dataclass, field\r\nfrom enum import Enum\r\nimport subprocess\r\nimport os\r\n\r\nclass ProjectPhase(Enum):\r\n    PLANNING = "planning"\r\n    IMPLEMENTATION = "implementation"\r\n    TESTING = "testing"\r\n    DEPLOYMENT = "deployment"\r\n    EVALUATION = "evaluation"\r\n\r\nclass ComponentType(Enum):\r\n    VISION = "vision"\r\n    LANGUAGE = "language"\r\n    ACTION = "action"\r\n    CONTROL = "control"\r\n    NAVIGATION = "navigation"\r\n    MANIPULATION = "manipulation"\r\n\r\n@dataclass\r\nclass ProjectComponent:\r\n    """Represents a component of the humanoid project"""\r\n    name: str\r\n    component_type: ComponentType\r\n    dependencies: List[str]\r\n    implementation: Callable\r\n    test_function: Callable\r\n    status: str = "not_started"\r\n    performance_metrics: Dict[str, float] = field(default_factory=dict)\r\n\r\nclass CapstoneProjectManager:\r\n    """Manage the humanoid capstone project lifecycle"""\r\n    def __init__(self, project_name: str):\r\n        self.project_name = project_name\r\n        self.phase = ProjectPhase.PLANNING\r\n        self.components = {}\r\n        self.project_timeline = {}\r\n        self.resources = {}\r\n        self.risks = []\r\n        self.milestones = []\r\n        self.evaluation_criteria = {}\r\n\r\n    def add_component(self, name: str, component_type: ComponentType,\r\n                     implementation: Callable, test_function: Callable,\r\n                     dependencies: List[str] = None):\r\n        """Add a component to the project"""\r\n        if dependencies is None:\r\n            dependencies = []\r\n\r\n        component = ProjectComponent(\r\n            name=name,\r\n            component_type=component_type,\r\n            dependencies=dependencies,\r\n            implementation=implementation,\r\n            test_function=test_function\r\n        )\r\n\r\n        self.components[name] = component\r\n        print(f"Added component: {name} ({component_type.value})")\r\n\r\n    def plan_project(self):\r\n        """Plan the project timeline and resource allocation"""\r\n        print(f"Planning project: {self.project_name}")\r\n\r\n        # Define project phases and timelines\r\n        self.project_timeline = {\r\n            ProjectPhase.PLANNING: {"start": 0, "end": 2, "duration": 2},  # weeks\r\n            ProjectPhase.IMPLEMENTATION: {"start": 2, "end": 8, "duration": 6},\r\n            ProjectPhase.TESTING: {"start": 8, "end": 10, "duration": 2},\r\n            ProjectPhase.DEPLOYMENT: {"start": 10, "end": 11, "duration": 1},\r\n            ProjectPhase.EVALUATION: {"start": 11, "end": 12, "duration": 1}\r\n        }\r\n\r\n        # Define resources needed\r\n        self.resources = {\r\n            "humanoid_robot": 1,\r\n            "development_workstations": 2,\r\n            "simulation_environment": 1,\r\n            "testing_space": 1,\r\n            "project_team": ["developer_1", "developer_2", "tester"]\r\n        }\r\n\r\n        # Define evaluation criteria\r\n        self.evaluation_criteria = {\r\n            "functionality": 0.4,  # 40% weight\r\n            "performance": 0.25,   # 25% weight\r\n            "reliability": 0.2,    # 20% weight\r\n            "innovation": 0.15     # 15% weight\r\n        }\r\n\r\n        print("Project planning completed")\r\n\r\n    def implement_component(self, component_name: str):\r\n        """Implement a specific component"""\r\n        if component_name not in self.components:\r\n            print(f"Component {component_name} not found")\r\n            return False\r\n\r\n        component = self.components[component_name]\r\n\r\n        # Check dependencies\r\n        for dep in component.dependencies:\r\n            if dep not in self.components or self.components[dep].status != "completed":\r\n                print(f"Dependency {dep} not satisfied for {component_name}")\r\n                return False\r\n\r\n        try:\r\n            print(f"Implementing component: {component_name}")\r\n            component.implementation()\r\n            component.status = "completed"\r\n            print(f"Component {component_name} implemented successfully")\r\n            return True\r\n        except Exception as e:\r\n            print(f"Error implementing component {component_name}: {e}")\r\n            component.status = "failed"\r\n            return False\r\n\r\n    def test_component(self, component_name: str):\r\n        """Test a specific component"""\r\n        if component_name not in self.components:\r\n            print(f"Component {component_name} not found")\r\n            return False\r\n\r\n        component = self.components[component_name]\r\n\r\n        if component.status != "completed":\r\n            print(f"Component {component_name} not implemented yet")\r\n            return False\r\n\r\n        try:\r\n            print(f"Testing component: {component_name}")\r\n            success, metrics = component.test_function()\r\n            component.performance_metrics = metrics\r\n            component.status = "tested" if success else "failed_testing"\r\n            print(f"Component {component_name} test {\'passed\' if success else \'failed\'}")\r\n            return success\r\n        except Exception as e:\r\n            print(f"Error testing component {component_name}: {e}")\r\n            component.status = "failed_testing"\r\n            return False\r\n\r\n    def evaluate_project(self):\r\n        """Evaluate the complete project"""\r\n        print(f"Evaluating project: {self.project_name}")\r\n\r\n        # Calculate component completion\r\n        completed_components = sum(1 for comp in self.components.values() if comp.status == "tested")\r\n        total_components = len(self.components)\r\n        completion_rate = completed_components / total_components if total_components > 0 else 0\r\n\r\n        # Calculate weighted scores\r\n        functionality_score = self.calculate_functionality_score()\r\n        performance_score = self.calculate_performance_score()\r\n        reliability_score = self.calculate_reliability_score()\r\n        innovation_score = self.calculate_innovation_score()\r\n\r\n        # Overall score\r\n        overall_score = (\r\n            functionality_score * self.evaluation_criteria["functionality"] +\r\n            performance_score * self.evaluation_criteria["performance"] +\r\n            reliability_score * self.evaluation_criteria["reliability"] +\r\n            innovation_score * self.evaluation_criteria["innovation"]\r\n        )\r\n\r\n        evaluation_results = {\r\n            "completion_rate": completion_rate,\r\n            "functionality_score": functionality_score,\r\n            "performance_score": performance_score,\r\n            "reliability_score": reliability_score,\r\n            "innovation_score": innovation_score,\r\n            "overall_score": overall_score,\r\n            "total_components": total_components,\r\n            "completed_components": completed_components\r\n        }\r\n\r\n        print(f"Project evaluation completed:")\r\n        for key, value in evaluation_results.items():\r\n            print(f"  {key}: {value}")\r\n\r\n        return evaluation_results\r\n\r\n    def calculate_functionality_score(self) -> float:\r\n        """Calculate functionality score based on component implementation"""\r\n        if not self.components:\r\n            return 0.0\r\n\r\n        functional_components = sum(\r\n            1 for comp in self.components.values()\r\n            if comp.status == "tested" and comp.component_type in [\r\n                ComponentType.VISION, ComponentType.LANGUAGE, ComponentType.ACTION\r\n            ]\r\n        )\r\n\r\n        return functional_components / len([c for c in self.components.values() if c.component_type in [\r\n            ComponentType.VISION, ComponentType.LANGUAGE, ComponentType.ACTION\r\n        ]])\r\n\r\n    def calculate_performance_score(self) -> float:\r\n        """Calculate performance score based on metrics"""\r\n        if not self.components:\r\n            return 0.0\r\n\r\n        total_performance = 0.0\r\n        performance_count = 0\r\n\r\n        for comp in self.components.values():\r\n            if comp.performance_metrics:\r\n                # Average performance metrics\r\n                avg_metric = sum(comp.performance_metrics.values()) / len(comp.performance_metrics)\r\n                total_performance += avg_metric\r\n                performance_count += 1\r\n\r\n        return total_performance / performance_count if performance_count > 0 else 0.0\r\n\r\n    def calculate_reliability_score(self) -> float:\r\n        """Calculate reliability score"""\r\n        # This would be based on testing results and failure rates\r\n        successful_tests = sum(\r\n            1 for comp in self.components.values()\r\n            if comp.status == "tested"\r\n        )\r\n        total_tests = len(self.components)\r\n\r\n        return successful_tests / total_tests if total_tests > 0 else 0.0\r\n\r\n    def calculate_innovation_score(self) -> float:\r\n        """Calculate innovation score"""\r\n        # This would be based on novel approaches and creative solutions\r\n        # For now, return a placeholder score\r\n        return 0.8  # Assume good innovation\r\n\r\nclass CapstoneProjectNode(Node):\r\n    """ROS2 node for managing the capstone project"""\r\n    def __init__(self):\r\n        super().__init__(\'capstone_project_manager\')\r\n\r\n        # Publishers and subscribers\r\n        self.project_command_sub = self.create_subscription(\r\n            String, \'/capstone/command\', self.command_callback, 10)\r\n        self.project_status_pub = self.create_publisher(String, \'/capstone/status\', 10)\r\n        self.project_evaluation_pub = self.create_publisher(String, \'/capstone/evaluation\', 10)\r\n\r\n        # Initialize project manager\r\n        self.project_manager = CapstoneProjectManager("Humanoid_VLA_Assistant")\r\n\r\n        # Timer for project monitoring\r\n        self.monitor_timer = self.create_timer(1.0, self.monitor_project)\r\n\r\n        # Initialize project components\r\n        self.initialize_project_components()\r\n\r\n        self.get_logger().info(\'Capstone Project Manager initialized\')\r\n\r\n    def initialize_project_components(self):\r\n        """Initialize all project components"""\r\n        # Vision component\r\n        self.project_manager.add_component(\r\n            name="vision_system",\r\n            component_type=ComponentType.VISION,\r\n            implementation=self.implement_vision_system,\r\n            test_function=self.test_vision_system,\r\n            dependencies=[]\r\n        )\r\n\r\n        # Language component\r\n        self.project_manager.add_component(\r\n            name="language_system",\r\n            component_type=ComponentType.LANGUAGE,\r\n            implementation=self.implement_language_system,\r\n            test_function=self.test_language_system,\r\n            dependencies=["vision_system"]\r\n        )\r\n\r\n        # Action component\r\n        self.project_manager.add_component(\r\n            name="action_system",\r\n            component_type=ComponentType.ACTION,\r\n            implementation=self.implement_action_system,\r\n            test_function=self.test_action_system,\r\n            dependencies=["language_system"]\r\n        )\r\n\r\n        # Navigation component\r\n        self.project_manager.add_component(\r\n            name="navigation_system",\r\n            component_type=ComponentType.NAVIGATION,\r\n            implementation=self.implement_navigation_system,\r\n            test_function=self.test_navigation_system,\r\n            dependencies=["vision_system", "action_system"]\r\n        )\r\n\r\n        # Manipulation component\r\n        self.project_manager.add_component(\r\n            name="manipulation_system",\r\n            component_type=ComponentType.MANIPULATION,\r\n            implementation=self.implement_manipulation_system,\r\n            test_function=self.test_manipulation_system,\r\n            dependencies=["vision_system", "action_system"]\r\n        )\r\n\r\n        # Plan the project\r\n        self.project_manager.plan_project()\r\n\r\n    def command_callback(self, msg):\r\n        """Process project commands"""\r\n        try:\r\n            command_data = json.loads(msg.data)\r\n            command_type = command_data.get("command")\r\n            target = command_data.get("target")\r\n\r\n            if command_type == "start_implementation":\r\n                self.start_implementation_phase()\r\n            elif command_type == "test_component":\r\n                success = self.project_manager.test_component(target)\r\n                self.publish_status(f"Test {\'passed\' if success else \'failed\'} for {target}")\r\n            elif command_type == "evaluate_project":\r\n                results = self.project_manager.evaluate_project()\r\n                self.publish_evaluation(results)\r\n            elif command_type == "get_status":\r\n                status = self.get_project_status()\r\n                self.publish_status(json.dumps(status))\r\n\r\n        except json.JSONDecodeError:\r\n            self.get_logger().error(f"Invalid JSON command: {msg.data}")\r\n\r\n    def start_implementation_phase(self):\r\n        """Start the implementation phase"""\r\n        self.get_logger().info("Starting implementation phase")\r\n\r\n        # Implement all components\r\n        for component_name in self.project_manager.components:\r\n            success = self.project_manager.implement_component(component_name)\r\n            if not success:\r\n                self.get_logger().error(f"Failed to implement {component_name}")\r\n\r\n    def implement_vision_system(self):\r\n        """Implementation function for vision system"""\r\n        time.sleep(0.1)  # Simulate implementation time\r\n        print("Vision system implemented")\r\n\r\n    def test_vision_system(self):\r\n        """Test function for vision system"""\r\n        time.sleep(0.05)  # Simulate test time\r\n        success = True  # Simulate success\r\n        metrics = {"accuracy": 0.95, "fps": 30.0}\r\n        print("Vision system tested")\r\n        return success, metrics\r\n\r\n    def implement_language_system(self):\r\n        """Implementation function for language system"""\r\n        time.sleep(0.1)\r\n        print("Language system implemented")\r\n\r\n    def test_language_system(self):\r\n        """Test function for language system"""\r\n        time.sleep(0.05)\r\n        success = True\r\n        metrics = {"understanding_rate": 0.92, "response_time": 1.2}\r\n        print("Language system tested")\r\n        return success, metrics\r\n\r\n    def implement_action_system(self):\r\n        """Implementation function for action system"""\r\n        time.sleep(0.1)\r\n        print("Action system implemented")\r\n\r\n    def test_action_system(self):\r\n        """Test function for action system"""\r\n        time.sleep(0.05)\r\n        success = True\r\n        metrics = {"execution_success": 0.98, "precision": 0.02}\r\n        print("Action system tested")\r\n        return success, metrics\r\n\r\n    def implement_navigation_system(self):\r\n        """Implementation function for navigation system"""\r\n        time.sleep(0.1)\r\n        print("Navigation system implemented")\r\n\r\n    def test_navigation_system(self):\r\n        """Test function for navigation system"""\r\n        time.sleep(0.05)\r\n        success = True\r\n        metrics = {"navigation_success": 0.94, "path_efficiency": 0.88}\r\n        print("Navigation system tested")\r\n        return success, metrics\r\n\r\n    def implement_manipulation_system(self):\r\n        """Implementation function for manipulation system"""\r\n        time.sleep(0.1)\r\n        print("Manipulation system implemented")\r\n\r\n    def test_manipulation_system(self):\r\n        """Test function for manipulation system"""\r\n        time.sleep(0.05)\r\n        success = True\r\n        metrics = {"grasp_success": 0.91, "placement_accuracy": 0.96}\r\n        print("Manipulation system tested")\r\n        return success, metrics\r\n\r\n    def get_project_status(self):\r\n        """Get current project status"""\r\n        status = {\r\n            "project_name": self.project_manager.project_name,\r\n            "phase": self.project_manager.phase.value,\r\n            "components": {\r\n                name: {\r\n                    "status": comp.status,\r\n                    "type": comp.component_type.value,\r\n                    "metrics": comp.performance_metrics\r\n                }\r\n                for name, comp in self.project_manager.components.items()\r\n            },\r\n            "timeline": self.project_manager.project_timeline,\r\n            "resources": self.project_manager.resources\r\n        }\r\n        return status\r\n\r\n    def monitor_project(self):\r\n        """Monitor project progress"""\r\n        status = self.get_project_status()\r\n        status_msg = String()\r\n        status_msg.data = json.dumps(status, indent=2)\r\n        self.project_status_pub.publish(status_msg)\r\n\r\n    def publish_status(self, status_text: str):\r\n        """Publish status message"""\r\n        status_msg = String()\r\n        status_msg.data = status_text\r\n        self.project_status_pub.publish(status_msg)\r\n\r\n    def publish_evaluation(self, evaluation_results: Dict):\r\n        """Publish evaluation results"""\r\n        eval_msg = String()\r\n        eval_msg.data = json.dumps(evaluation_results, indent=2)\r\n        self.project_evaluation_pub.publish(eval_msg)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = CapstoneProjectNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down capstone project manager...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"humanoid-safety-and-performance-monitoring",children:"Humanoid Safety and Performance Monitoring"}),"\n",(0,s.jsx)(n.p,{children:"System for monitoring humanoid robot safety and performance during operation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nHumanoid Safety and Performance Monitoring\r\nSystem for monitoring humanoid robot safety and performance during operation\r\n"""\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String, Bool, Float64\r\nfrom sensor_msgs.msg import JointState, Imu, BatteryState\r\nfrom geometry_msgs.msg import Twist, Pose\r\nfrom diagnostic_msgs.msg import DiagnosticArray, DiagnosticStatus, KeyValue\r\nimport numpy as np\r\nimport time\r\nfrom typing import Dict, List\r\nimport threading\r\nfrom dataclasses import dataclass\r\nfrom enum import Enum\r\n\r\nclass SafetyLevel(Enum):\r\n    SAFE = "safe"\r\n    WARNING = "warning"\r\n    DANGER = "danger"\r\n    CRITICAL = "critical"\r\n\r\nclass PerformanceMetric(Enum):\r\n    STABILITY = "stability"\r\n    BALANCE = "balance"\r\n    POWER = "power"\r\n    JOINT_HEALTH = "joint_health"\r\n    NAVIGATION_ACCURACY = "navigation_accuracy"\r\n\r\n@dataclass\r\nclass SafetyThresholds:\r\n    """Safety thresholds for different parameters"""\r\n    max_joint_temp: float = 70.0  # Celsius\r\n    max_current: float = 10.0    # Amps\r\n    max_imu_angle: float = 30.0  # Degrees\r\n    min_battery: float = 20.0    # Percentage\r\n    max_power_consumption: float = 500.0  # Watts\r\n\r\nclass SafetyMonitor:\r\n    """Monitor safety parameters of the humanoid robot"""\r\n    def __init__(self):\r\n        self.thresholds = SafetyThresholds()\r\n        self.current_readings = {\r\n            \'joint_temps\': {},\r\n            \'joint_currents\': {},\r\n            \'imu_angles\': np.array([0.0, 0.0, 0.0]),\r\n            \'battery_level\': 100.0,\r\n            \'power_consumption\': 0.0\r\n        }\r\n        self.safety_history = []\r\n        self.max_history = 100\r\n\r\n    def update_joint_state(self, joint_state: JointState):\r\n        """Update with joint state information"""\r\n        for i, name in enumerate(joint_state.name):\r\n            if i < len(joint_state.effort):  # Using effort as proxy for current\r\n                self.current_readings[\'joint_currents\'][name] = joint_state.effort[i]\r\n            # In real implementation, temperature would come from separate messages\r\n\r\n    def update_imu_data(self, imu_data):\r\n        """Update with IMU data for balance monitoring"""\r\n        # Convert quaternion to Euler angles (simplified)\r\n        w, x, y, z = imu_data.orientation.w, imu_data.orientation.x, imu_data.orientation.y, imu_data.orientation.z\r\n\r\n        # Roll (x-axis rotation)\r\n        sinr_cosp = 2 * (w * x + y * z)\r\n        cosr_cosp = 1 - 2 * (x * x + y * y)\r\n        roll = np.arctan2(sinr_cosp, cosr_cosp)\r\n\r\n        # Pitch (y-axis rotation)\r\n        sinp = 2 * (w * y - z * x)\r\n        pitch = np.arcsin(sinp)\r\n\r\n        # Yaw (z-axis rotation)\r\n        siny_cosp = 2 * (w * z + x * y)\r\n        cosy_cosp = 1 - 2 * (y * y + z * z)\r\n        yaw = np.arctan2(siny_cosp, cosy_cosp)\r\n\r\n        self.current_readings[\'imu_angles\'] = np.array([roll, pitch, yaw]) * 180 / np.pi  # Convert to degrees\r\n\r\n    def update_battery_data(self, battery_data):\r\n        """Update with battery information"""\r\n        self.current_readings[\'battery_level\'] = battery_data.percentage * 100\r\n\r\n    def check_safety(self) -> SafetyLevel:\r\n        """Check current safety status"""\r\n        safety_issues = []\r\n\r\n        # Check joint temperatures (simulated)\r\n        for joint, temp in self.current_readings[\'joint_temps\'].items():\r\n            if temp > self.thresholds.max_joint_temp:\r\n                safety_issues.append(f"High temperature in {joint}: {temp}\xb0C")\r\n\r\n        # Check joint currents\r\n        for joint, current in self.current_readings[\'joint_currents\'].items():\r\n            if abs(current) > self.thresholds.max_current:\r\n                safety_issues.append(f"High current in {joint}: {current}A")\r\n\r\n        # Check IMU angles (balance)\r\n        max_angle = np.max(np.abs(self.current_readings[\'imu_angles\']))\r\n        if max_angle > self.thresholds.max_imu_angle:\r\n            safety_issues.append(f"Balance exceeded: {max_angle}\xb0")\r\n\r\n        # Check battery level\r\n        if self.current_readings[\'battery_level\'] < self.thresholds.min_battery:\r\n            safety_issues.append(f"Low battery: {self.current_readings[\'battery_level\']:.1f}%")\r\n\r\n        # Determine safety level\r\n        if len(safety_issues) == 0:\r\n            level = SafetyLevel.SAFE\r\n        elif len(safety_issues) == 1:\r\n            level = SafetyLevel.WARNING\r\n        elif len(safety_issues) <= 3:\r\n            level = SafetyLevel.DANGER\r\n        else:\r\n            level = SafetyLevel.CRITICAL\r\n\r\n        # Store in history\r\n        self.safety_history.append({\r\n            \'timestamp\': time.time(),\r\n            \'level\': level,\r\n            \'issues\': safety_issues.copy()\r\n        })\r\n\r\n        if len(self.safety_history) > self.max_history:\r\n            self.safety_history.pop(0)\r\n\r\n        return level\r\n\r\n    def get_safety_report(self) -> Dict:\r\n        """Get detailed safety report"""\r\n        current_level = self.check_safety()\r\n        return {\r\n            \'current_level\': current_level.value,\r\n            \'readings\': self.current_readings,\r\n            \'issues\': self.safety_history[-1][\'issues\'] if self.safety_history else [],\r\n            \'history_count\': len(self.safety_history)\r\n        }\r\n\r\nclass PerformanceMonitor:\r\n    """Monitor performance metrics of the humanoid robot"""\r\n    def __init__(self):\r\n        self.metrics = {\r\n            PerformanceMetric.STABILITY: [],\r\n            PerformanceMetric.BALANCE: [],\r\n            PerformanceMetric.POWER: [],\r\n            PerformanceMetric.JOINT_HEALTH: [],\r\n            PerformanceMetric.NAVIGATION_ACCURACY: []\r\n        }\r\n        self.max_history = 50\r\n\r\n    def update_stability(self, stability_score: float):\r\n        """Update stability metric"""\r\n        self._add_metric(PerformanceMetric.STABILITY, stability_score)\r\n\r\n    def update_balance(self, balance_score: float):\r\n        """Update balance metric"""\r\n        self._add_metric(PerformanceMetric.BALANCE, balance_score)\r\n\r\n    def update_power(self, power_usage: float):\r\n        """Update power metric"""\r\n        self._add_metric(PerformanceMetric.POWER, power_usage)\r\n\r\n    def update_joint_health(self, health_score: float):\r\n        """Update joint health metric"""\r\n        self._add_metric(PerformanceMetric.JOINT_HEALTH, health_score)\r\n\r\n    def update_navigation_accuracy(self, accuracy_score: float):\r\n        """Update navigation accuracy metric"""\r\n        self._add_metric(PerformanceMetric.NAVIGATION_ACCURACY, accuracy_score)\r\n\r\n    def _add_metric(self, metric: PerformanceMetric, value: float):\r\n        """Add value to metric history"""\r\n        self.metrics[metric].append(value)\r\n        if len(self.metrics[metric]) > self.max_history:\r\n            self.metrics[metric].pop(0)\r\n\r\n    def get_performance_summary(self) -> Dict:\r\n        """Get performance summary with averages"""\r\n        summary = {}\r\n        for metric, values in self.metrics.items():\r\n            if values:\r\n                avg_value = sum(values) / len(values)\r\n                summary[metric.value] = {\r\n                    \'average\': avg_value,\r\n                    \'latest\': values[-1],\r\n                    \'count\': len(values),\r\n                    \'trend\': self._calculate_trend(values)\r\n                }\r\n            else:\r\n                summary[metric.value] = {\r\n                    \'average\': 0.0,\r\n                    \'latest\': 0.0,\r\n                    \'count\': 0,\r\n                    \'trend\': \'stable\'\r\n                }\r\n        return summary\r\n\r\n    def _calculate_trend(self, values: List[float]) -> str:\r\n        """Calculate trend of metric values"""\r\n        if len(values) < 2:\r\n            return \'stable\'\r\n\r\n        # Simple trend calculation based on last few values\r\n        recent_values = values[-5:] if len(values) >= 5 else values\r\n        if len(recent_values) < 2:\r\n            return \'stable\'\r\n\r\n        # Calculate linear trend\r\n        x = list(range(len(recent_values)))\r\n        y = recent_values\r\n        if len(x) > 1:\r\n            # Simple linear regression slope calculation\r\n            n = len(x)\r\n            slope = (n * sum(x[i] * y[i] for i in range(n)) - sum(x) * sum(y)) / (n * sum(xi**2 for xi in x) - sum(x)**2)\r\n            if slope > 0.01:\r\n                return \'improving\'\r\n            elif slope < -0.01:\r\n                return \'declining\'\r\n            else:\r\n                return \'stable\'\r\n        return \'stable\'\r\n\r\nclass HumanoidSafetyNode(Node):\r\n    """ROS2 node for humanoid safety and performance monitoring"""\r\n    def __init__(self):\r\n        super().__init__(\'humanoid_safety_monitor\')\r\n\r\n        # Publishers and subscribers\r\n        self.joint_state_sub = self.create_subscription(\r\n            JointState, \'/joint_states\', self.joint_state_callback, 10)\r\n        self.imu_sub = self.create_subscription(\r\n            Imu, \'/imu/data\', self.imu_callback, 10)\r\n        self.battery_sub = self.create_subscription(\r\n            BatteryState, \'/battery_state\', self.battery_callback, 10)\r\n        self.cmd_vel_sub = self.create_subscription(\r\n            Twist, \'/cmd_vel\', self.velocity_callback, 10)\r\n\r\n        self.safety_pub = self.create_publisher(DiagnosticArray, \'/safety_status\', 10)\r\n        self.performance_pub = self.create_publisher(String, \'/performance_metrics\', 10)\r\n        self.emergency_stop_pub = self.create_publisher(Bool, \'/emergency_stop\', 10)\r\n\r\n        # Initialize monitors\r\n        self.safety_monitor = SafetyMonitor()\r\n        self.performance_monitor = PerformanceMonitor()\r\n\r\n        # Emergency state\r\n        self.emergency_active = False\r\n\r\n        # Timer for safety checks\r\n        self.safety_timer = self.create_timer(0.1, self.safety_check_callback)  # 10Hz\r\n\r\n        self.get_logger().info(\'Humanoid Safety Monitor initialized\')\r\n\r\n    def joint_state_callback(self, msg):\r\n        """Process joint state updates"""\r\n        self.safety_monitor.update_joint_state(msg)\r\n\r\n        # Update performance metrics based on joint behavior\r\n        if len(msg.position) > 0:\r\n            # Calculate joint smoothness as a performance metric\r\n            smoothness = self._calculate_joint_smoothness(msg.position)\r\n            self.performance_monitor.update_joint_health(smoothness)\r\n\r\n    def imu_callback(self, msg):\r\n        """Process IMU updates"""\r\n        self.safety_monitor.update_imu_data(msg)\r\n\r\n        # Update balance performance metric\r\n        balance_score = self._calculate_balance_score(msg.orientation)\r\n        self.performance_monitor.update_balance(balance_score)\r\n\r\n    def battery_callback(self, msg):\r\n        """Process battery updates"""\r\n        self.safety_monitor.update_battery_data(msg)\r\n\r\n        # Update power performance metric\r\n        power_score = msg.percentage * 100  # Use battery level as proxy for power management\r\n        self.performance_monitor.update_power(power_score)\r\n\r\n    def velocity_callback(self, msg):\r\n        """Process velocity commands for performance monitoring"""\r\n        # Calculate stability based on commanded velocity\r\n        velocity_magnitude = np.sqrt(msg.linear.x**2 + msg.linear.y**2 + msg.angular.z**2)\r\n        stability_score = max(0, 1 - velocity_magnitude / 2.0)  # Normalize to 0-1 scale\r\n        self.performance_monitor.update_stability(stability_score)\r\n\r\n    def safety_check_callback(self):\r\n        """Perform safety check and publish status"""\r\n        # Check safety level\r\n        safety_level = self.safety_monitor.check_safety()\r\n\r\n        # Create diagnostic message\r\n        diag_array = DiagnosticArray()\r\n        diag_array.header.stamp = self.get_clock().now().to_msg()\r\n\r\n        diag_status = DiagnosticStatus()\r\n        diag_status.name = "Humanoid Safety Monitor"\r\n        diag_status.hardware_id = "humanoid_robot"\r\n\r\n        # Set status level based on safety\r\n        if safety_level == SafetyLevel.SAFE:\r\n            diag_status.level = DiagnosticStatus.OK\r\n            diag_status.message = "All systems nominal"\r\n        elif safety_level == SafetyLevel.WARNING:\r\n            diag_status.level = DiagnosticStatus.WARN\r\n            diag_status.message = "Safety warnings present"\r\n        else:\r\n            diag_status.level = DiagnosticStatus.ERROR\r\n            diag_status.message = f"Safety issues detected: {safety_level.value}"\r\n\r\n        # Add key metrics as values\r\n        readings = self.safety_monitor.current_readings\r\n        diag_status.values = []\r\n\r\n        # Add battery level\r\n        battery_kv = KeyValue()\r\n        battery_kv.key = "Battery Level (%)"\r\n        battery_kv.value = f"{readings[\'battery_level\']:.1f}"\r\n        diag_status.values.append(battery_kv)\r\n\r\n        # Add max IMU angle\r\n        max_angle = np.max(np.abs(readings[\'imu_angles\']))\r\n        angle_kv = KeyValue()\r\n        angle_kv.key = "Max IMU Angle (deg)"\r\n        angle_kv.value = f"{max_angle:.1f}"\r\n        diag_status.values.append(angle_kv)\r\n\r\n        # Add joint current info\r\n        if readings[\'joint_currents\']:\r\n            avg_current = sum(abs(c) for c in readings[\'joint_currents\'].values()) / len(readings[\'joint_currents\'])\r\n            current_kv = KeyValue()\r\n            current_kv.key = "Avg Joint Current (A)"\r\n            current_kv.value = f"{avg_current:.2f}"\r\n            diag_status.values.append(current_kv)\r\n\r\n        diag_array.status.append(diag_status)\r\n        self.safety_pub.publish(diag_array)\r\n\r\n        # Check if emergency stop is needed\r\n        if safety_level in [SafetyLevel.DANGER, SafetyLevel.CRITICAL]:\r\n            if not self.emergency_active:\r\n                self.trigger_emergency_stop()\r\n        elif safety_level == SafetyLevel.SAFE and self.emergency_active:\r\n            self.clear_emergency_stop()\r\n\r\n        # Publish performance metrics\r\n        perf_summary = self.performance_monitor.get_performance_summary()\r\n        perf_msg = String()\r\n        perf_msg.data = str(perf_summary)\r\n        self.performance_pub.publish(perf_msg)\r\n\r\n    def trigger_emergency_stop(self):\r\n        """Trigger emergency stop"""\r\n        self.emergency_active = True\r\n        stop_msg = Bool()\r\n        stop_msg.data = True\r\n        self.emergency_stop_pub.publish(stop_msg)\r\n        self.get_logger().error(\'EMERGENCY STOP ACTIVATED\')\r\n\r\n    def clear_emergency_stop(self):\r\n        """Clear emergency stop"""\r\n        self.emergency_active = False\r\n        stop_msg = Bool()\r\n        stop_msg.data = False\r\n        self.emergency_stop_pub.publish(stop_msg)\r\n        self.get_logger().info(\'Emergency stop cleared\')\r\n\r\n    def _calculate_joint_smoothness(self, positions: List[float]) -> float:\r\n        """Calculate joint smoothness metric"""\r\n        if len(positions) < 2:\r\n            return 1.0  # Perfect smoothness if only one value\r\n\r\n        # Calculate smoothness based on position changes\r\n        diffs = [abs(positions[i] - positions[i-1]) for i in range(1, len(positions))]\r\n        avg_diff = sum(diffs) / len(diffs) if diffs else 0\r\n\r\n        # Convert to smoothness score (0-1, where 1 is very smooth)\r\n        smoothness = max(0, 1 - avg_diff)\r\n        return smoothness\r\n\r\n    def _calculate_balance_score(self, orientation) -> float:\r\n        """Calculate balance score from orientation"""\r\n        # Convert quaternion to roll/pitch angles\r\n        w, x, y, z = orientation.w, orientation.x, orientation.y, orientation.z\r\n\r\n        sinr_cosp = 2 * (w * x + y * z)\r\n        cosr_cosp = 1 - 2 * (x * x + y * y)\r\n        roll = np.arctan2(sinr_cosp, cosr_cosp)\r\n\r\n        sinp = 2 * (w * y - z * x)\r\n        pitch = np.arcsin(sinp)\r\n\r\n        # Calculate balance score based on deviation from upright\r\n        angle_deviation = np.sqrt(roll**2 + pitch**2)\r\n        balance_score = max(0, 1 - angle_deviation / (np.pi/4))  # Normalize to 0-1 scale\r\n        return balance_score\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = HumanoidSafetyNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down humanoid safety monitor...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,s.jsx)(n.h3,{id:"humanoid-service-robot",children:"Humanoid Service Robot"}),"\n",(0,s.jsx)(n.p,{children:"Students develop a complete humanoid service robot that can understand commands, navigate spaces, and perform tasks in human environments."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Objectives:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Integrate vision, language, and action systems"}),"\n",(0,s.jsx)(n.li,{children:"Implement safe humanoid locomotion and manipulation"}),"\n",(0,s.jsx)(n.li,{children:"Create intuitive human-robot interaction"}),"\n",(0,s.jsx)(n.li,{children:"Validate system in realistic service scenarios"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required Components:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Humanoid robot platform"}),"\n",(0,s.jsx)(n.li,{children:"Vision system (cameras, processing)"}),"\n",(0,s.jsx)(n.li,{children:"Natural language processing tools"}),"\n",(0,s.jsx)(n.li,{children:"Manipulation system (arms, grippers)"}),"\n",(0,s.jsx)(n.li,{children:"Navigation and mapping capabilities"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Evaluation Criteria:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Task completion success rate"}),"\n",(0,s.jsx)(n.li,{children:"Human-robot interaction quality"}),"\n",(0,s.jsx)(n.li,{children:"System safety and reliability"}),"\n",(0,s.jsx)(n.li,{children:"Adaptation to dynamic environments"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"humanoid-research-platform",children:"Humanoid Research Platform"}),"\n",(0,s.jsx)(n.p,{children:"Students create a humanoid research platform for studying human-robot interaction and autonomous behavior."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Objectives:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Design modular humanoid architecture"}),"\n",(0,s.jsx)(n.li,{children:"Implement advanced perception systems"}),"\n",(0,s.jsx)(n.li,{children:"Create research experiment interfaces"}),"\n",(0,s.jsx)(n.li,{children:"Validate platform capabilities"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required Components:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Modular robot hardware"}),"\n",(0,s.jsx)(n.li,{children:"Research software framework"}),"\n",(0,s.jsx)(n.li,{children:"Data collection systems"}),"\n",(0,s.jsx)(n.li,{children:"Experiment control interfaces"}),"\n",(0,s.jsx)(n.li,{children:"Safety monitoring systems"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Evaluation Criteria:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Modularity and extensibility"}),"\n",(0,s.jsx)(n.li,{children:"Research capability and flexibility"}),"\n",(0,s.jsx)(n.li,{children:"Data quality and collection"}),"\n",(0,s.jsx)(n.li,{children:"System reliability for research"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"humanoid-educational-assistant",children:"Humanoid Educational Assistant"}),"\n",(0,s.jsx)(n.p,{children:"Students build an educational humanoid assistant that can help with teaching and learning activities."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Objectives:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Implement educational interaction patterns"}),"\n",(0,s.jsx)(n.li,{children:"Create adaptive learning capabilities"}),"\n",(0,s.jsx)(n.li,{children:"Develop child-friendly interfaces"}),"\n",(0,s.jsx)(n.li,{children:"Test effectiveness in educational settings"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required Components:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Child-safe robot platform"}),"\n",(0,s.jsx)(n.li,{children:"Educational content system"}),"\n",(0,s.jsx)(n.li,{children:"Adaptive learning algorithms"}),"\n",(0,s.jsx)(n.li,{children:"Safety and monitoring systems"}),"\n",(0,s.jsx)(n.li,{children:"Educational assessment tools"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Evaluation Criteria:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Educational effectiveness"}),"\n",(0,s.jsx)(n.li,{children:"User engagement and satisfaction"}),"\n",(0,s.jsx)(n.li,{children:"Safety in educational environments"}),"\n",(0,s.jsx)(n.li,{children:"Adaptation to different learners"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Chapter 20 provided comprehensive capstone project examples integrating all VLA and humanoid concepts. Students learned to develop end-to-end humanoid systems combining vision, language, and action capabilities with safety monitoring and performance evaluation. The chapter emphasized system integration, project management, and real-world deployment considerations for creating sophisticated humanoid robots capable of complex human interaction."}),"\n",(0,s.jsx)(n.h2,{id:"quiz",children:"Quiz"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What is the main purpose of a capstone project in humanoid robotics?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A: To eliminate the need for further learning"}),"\n",(0,s.jsx)(n.li,{children:"B: To integrate all learned concepts into comprehensive systems"}),"\n",(0,s.jsx)(n.li,{children:"C: To reduce hardware requirements"}),"\n",(0,s.jsx)(n.li,{children:"D: To make robots move faster"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer: B"})," - Capstone projects integrate all learned concepts into comprehensive systems that solve real-world challenges."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Why is safety monitoring crucial in humanoid robot projects?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A: It makes robots cheaper"}),"\n",(0,s.jsx)(n.li,{children:"B: It ensures safe operation around humans and prevents damage"}),"\n",(0,s.jsx)(n.li,{children:"C: It reduces power consumption"}),"\n",(0,s.jsx)(n.li,{children:"D: It eliminates the need for programming"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer: B"})," - Safety monitoring ensures safe operation around humans and prevents damage to the robot and environment."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What does system integration mean in humanoid robotics?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A: Connecting multiple robots together"}),"\n",(0,s.jsx)(n.li,{children:"B: Combining vision, language, and action components into unified systems"}),"\n",(0,s.jsx)(n.li,{children:"C: Using only one type of sensor"}),"\n",(0,s.jsx)(n.li,{children:"D: Making robots physically larger"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer: B"})," - System integration combines vision, language, and action components into unified, functional systems."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Why is performance evaluation important in humanoid projects?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A: It makes robots move faster"}),"\n",(0,s.jsx)(n.li,{children:"B: It measures success across multiple dimensions and guides improvements"}),"\n",(0,s.jsx)(n.li,{children:"C: It reduces hardware costs"}),"\n",(0,s.jsx)(n.li,{children:"D: It eliminates the need for testing"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer: B"})," - Performance evaluation measures success across multiple dimensions and guides system improvements."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What is multi-modal fusion in humanoid systems?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A: Using multiple programming languages"}),"\n",(0,s.jsx)(n.li,{children:"B: Integrating information from different sensory modalities"}),"\n",(0,s.jsx)(n.li,{children:"C: Using multiple robots at once"}),"\n",(0,s.jsx)(n.li,{children:"D: Making robots speak multiple languages"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Answer: B"})," - Multi-modal fusion integrates information from different sensory modalities (vision, language, etc.) for better understanding."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,s.jsx)(n.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Implement multimodal learning systems"}),"\n",(0,s.jsx)(n.li,{children:"Integrate vision, language, and action components"}),"\n",(0,s.jsx)(n.li,{children:"Develop interactive learning algorithms"}),"\n",(0,s.jsx)(n.li,{children:"Create human-robot interaction systems"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Basic understanding of Python programming"}),"\n",(0,s.jsx)(n.li,{children:"Fundamentals of linear algebra and calculus"}),"\n",(0,s.jsx)(n.li,{children:"Basic knowledge of robotics concepts"}),"\n",(0,s.jsx)(n.li,{children:"Introduction to machine learning concepts"}),"\n",(0,s.jsx)(n.li,{children:"Completion of Module 0 (Introduction and Foundations)"}),"\n",(0,s.jsx)(n.li,{children:"Completion of all previous chapters in Module 4 (Chapters 16-19)"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"estimated-duration",children:"Estimated Duration"}),"\n",(0,s.jsx)(n.p,{children:"8 hours"})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>i});var t=r(6540);const s={},a=t.createContext(s);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);